This work was supported by a Medical Research Council Career Development Grant awarded to the first author and formed part of an ongoing
program of research at the Medical Research Council's Institute of Hearing Research, Nottingham, U.K. We would like to thank the consultants
and staff at the Queen's Medical Centre, Nottingham, who provided support as well as to the patients themselves for their participation.
Claims have been made for associated degrees of impairment on both visual and auditory performance in unilateral neglect and extinction.
Since this evidence is primarily based on different tests in each modality, it is difficult to properly quantify the degree of association
between performance in vision and audition. The current study compares visual and auditory extinction and temporal order judgments (TOJs) in
two cases with clinical visual neglect. Stimuli in both modalities were precisely matched in their temporal and spatial parameters. The
results reveal a mixed pattern of association between different auditory tests and their visual counterparts. This suggests that
associations between visual and auditory neglect can occur but these are neither obligatory nor pervasive. Instead, our data support models
of spatial impairment in neglect and extinction that acknowledge differences in the contribution of spatial information to performance in
each modality in responses to changing task demands. Unilateral neglect is a neurological syndrome associated with unilateral (predominantly
right) cortical lesions. It affects up to two thirds of acute right hemisphere stroke patients (Parton, Malhotra, & Husain, 2004) and
presents as a lack of awareness of objects and events on the side of space contralateral to the causal lesion (i.e., on the left side for a
patient with right hemisphere damage). These symptoms exist despite the absence of basic sensory deficits (e.g., hemianopia) and are often
attributed to an impairment of spatial representation and/or selective attention (e.g., E. Bisiach, 1993; Di Pellegrino, Basso, &
Frassinetti, 1997; Farah, Wong, Monheit, & Morrow, 1989; Mesulam, 1999; Rorden, Mattingley, Karnath, & Driver, 1997). In some cases,
contralesional neglect only occurs in the presence of a simultaneous ipsilesional object. This pattern of impairment, often called
extinction, is usually considered part of the neglect syndrome (Parton et al., 2004). Despite the fact that neglect and extinction are most
commonly described and diagnosed on the basis of visuospatial behavior, there is growing evidence that these deficits can occur in other
sensory modalities (e.g., Cusack et al., 2000; Eramudugolla, Irvine, & Mattingley, 2007; Pavani, Husain, Ladavas, & Driver, 2004; Pavani,
Ladavas, & Driver, 2003; Spierer, Meuli, & Clarke, 2007). Associations between visual, auditory, and tactile neglect suggest that the
syndrome reflects a perturbation of multimodal spatial selection and attention (E. Bisiach et al., 2004; L. Bisiach, Cornacchia, & Vallar,
1984; Bueti, Costantini, Forster, & Aglioti, 2004). Models ascribing visuospatial deficits in neglect and extinction to changes in the
distribution of neural activation representing stimuli presented in ipsilesional and contralesional space provide a theoretical account for
spatiotemporal deficits in other modalities (e.g., Cate & Behrmann, 2002; Kinsbourne, 1993; Rizzolati, Scandolara, Matelli, & Gentilucci,
1981). This has led researchers to extend models of visuospatial neglect and extinction to explain deficits in audition and touch (e.g.,
Pavani et al., 2004; Pavani et al., 2003). This generalization is given further support by behavioral (e.g., Driver & Spence, 1994; Spence &
Driver, 1997; Spence, Lloyd, McGlone, Nicholls, & Driver, 2000), neuroanatomical (see Ghazanfar & Schroeder, 2006, for a recent review), and
neuroimaging (Lewis, Beauchamp, & DeYoe, 2000; Macaluso, Frith, & Driver, 2001) evidence and further indicates that spatial location and
attention play an important part in multimodal integration. Despite the above, multimodal accounts of neglect and extinction remain somewhat
contentious (Golay, Hauert, Greber, Schnider, & Ptak, 2005; Sinnett, Juncadella, Rafal, Azanon, & Soto-Faraco, 2007; Spierer et al., 2007).
A number of studies have found dissociations between visual and auditory attentional biases in patients diagnosed with visual neglect (De
Renzi, Gentilini, & Barbieri, 1989; Soroker, Calamaro, Glicksohn, & Myslobodsky, 1997; Spierer et al., 2007; Zimmer, Lewald, & Karnath,
2003). These have been interpreted as evidence for selective damage to modality-specific mechanisms of spatial representation (e.g., De
Renzi, Gentilini, & Pattachini, 1984; Soroker et al., 1997). This assertion emphasizes potential differences in the role of spatial
selection in perceptual systems characterized by different coding principles (e.g., the spatiotopic visual and tonotopic auditory systems)
and is consistent with evidence for modality-specific spatial cuing effects in vision and audition (McDonald & Ward, 1999; Roberts,
Summerfield, & Hall, 2006). An alternative explanation is that the reported dissociations between measures of attentional bias may, in part,
reflect differences in the specificity and sensitivity of the visual and auditory tests employed rather than the nature of the underlying
impairment itself. Given the potential remedial utility afforded by intact auditory-spatial representation in patients with visual neglect
(Golay et al., 2005), it is important to establish the degree of association between visual and auditory impairment when potential
measurement artifacts are controlled. Much of the evidence for an association between visual and auditory attentional bias is based on tests
that place different demands on performance in each modality (e.g., Pavani et al., 2004; Pavani, Meneghello, & Ladavas, 2001; Pavani et al.,
2003). Neglect assessment typically utilizes clinical “pen and paper” tests that may include line bisection, cancellation, and copying from
sample tasks (e.g., Wilson, Cockburn, & Halligan, 1987). These are presented at the patient's bedside, with the patient being given
unlimited time to view the material and to make a manual response. Performance on these tasks draws heavily on visuomotor control (Parton et
al., 2004). In contrast, auditory neglect has typically been assessed using tasks in which the patient is asked to localize briefly
presented sounds and to make either a verbal or a simple manual response that is orthogonal to left and right (e.g., Pavani et al., 2003;
Pinek, Duhamel, Cave, & Brouchon, 1989). Differences in task demands have also been confounded by differences in the location to which
visual and auditory stimuli are presented. Most auditory tasks have used sounds presented over headphones (Bellmann, Meuli, & Clarke, 2001;
Karnath, Zimmer, & Lewald, 2002; Zimmer et al., 2003). These manipulate perceived location using binaural cues (interaural timing
differences, ITDs, and interaural level differences, ILDs; e.g., L. Bisiach et al., 1984; Zimmer et al., 2003) or monaural cues. A sound
presented to only one ear has an infinite ILD (e.g., Sinnett et al., 2007). This produces sounds that appear to arise from an intracranial
position, a location for which there is no visual counterpart (Blauert & Lindemann, 1986). Binaural cues also elicit a weak spatial percept
to which even normal listeners, without training, can have difficulty orienting attention (Roberts et al., 2006). The lack of a spatial
coincidence between auditory stimuli presented over headphones and visual stimuli presented in extrapersonal space means that stimuli in
either modality arise from different locations. Differences between binaural and monaural sounds can also make it difficult to distinguish
between the involvement of spatial representation on one hand and the perceptive extinction of information from one ear on the other.
Extinction for monaural sounds presented to the left ear and for binaural sounds lateralized to the left hemispace have also been shown to
dissociate, suggesting distinct underlying neural processes in each case (Bellman et al., 2001; Spierer et al., 2007). An alternative method
of sound presentation is to use head-related transfer functions. These generate virtual space by simulating the linear distortions in the
magnitude and phase spectrum of the acoustic signal on its path from the sound source to the eardrums, which are caused by shadowing,
reflection, and diffraction by the head and outer ear. These filter characteristics are known to disambiguate front–back confusions and
improve localization accuracy (Wenzel, Arruda, Kistler, & Wightman, 1993). Although this method improves the perception of auditory spatial
location for sounds presented over headphones, it is still not ideal as the sound source is rarely perceived as external unless personalized
transfer functions are used (Wenzel et al., 1993; Wightman & Kistler, 1989). Even when these or free-field sounds have been used to assess
auditory neglect in virtual or real space, comparative visual stimuli have either been absent (Bender & Diamond, 1965; Pavani, Lavadas, &
Driver, 2002; Soroker et al., 1997) or not matched for egocentric location. In Eramudugolla et al.'s (2007) study, for example, visual
stimuli were presented at eccentricities of 8.7 while auditory stimuli were presented at 90 from fixation. This lack of explicit matching
for location across visual and auditory tests has implications for the assessment of any multimodal spatial metric in neglect and makes
quantitative comparisons across sensory modalities difficult (but see Frassinetti et al., 2002, for a recent exception). The current paper
presents two case studies that examine the degree of correspondence between visual and auditory neglect and extinction using tasks carefully
designed to match the extrapersonal spatial and temporal parameters of stimuli in each modality. Unlike group studies, the case-by-case
approach allows direct comparisons of unimodal performance that are independent of variability introduced by differences in the site and
extent of lesions among patients in the sample (Caramazza & Badecker, 1989). Dissociations within a single case provide evidence for the
absolute or relative separation of neural processes underlying individual performance under different test conditions (see Shallice, 1988,
for a review of the logic underlying single-case methodology). In the first task, we report extinction indices that measure decrements in
the detection of dual compared to single objects as a function of their egocentric location. To our knowledge, this is the first time that
detection rates have been compared for visual and auditory stimuli presented at identical locations in the horizontal meridian (azimuth). In
the second task, sensitivity to temporal asynchrony between two stimuli is measured using a temporal order judgment (TOJ) task. Previous TOJ
results have revealed a temporal disadvantage for contralesional compared to ipsilesional stimuli (Di Pellegrino et al., 1997; Eramudugolla
et al., 2007; Karnath et al., 2002; Rorden et al., 1997). Our experiment extends these studies by evaluating spatiotemporal judgments using
visual and auditory stimuli that are matched precisely in terms of their spatial and temporal characteristics. Two patients (F.D. & J.B.)
were recruited from the stroke rehabilitation ward at the Queen's Medical Centre, Nottingham. F.D. suffered a right middle cerebral artery
(MCA) territory infarct resulting in low attenuation in the region of the superior right frontal lobe, caudate, and lentiform nucleus. J.B.
had a hyperacute right MCA territory infarction with hyperdense right MCA branches. Hypodensity was also observed in the right insula and
external capsules (radiographer's reports). Patients were assessed within one month of hospital admission (14 and 31 days) and undertook a
battery of clinical tests, including a star cancellation task, line bisection, and figure drawing from sample. Each demonstrated a pattern
of visuospatial performance consistent with a clinical diagnosis of neglect (see Table 1 for a clinical description for each patient). Both
patients had intact hemifields, and pure-tone audiometry revealed hearing within the range of age-matched controls (Davis, 1995). A total of
15 age-matched controls (mean = 66 years, SD = 2.5 years) were also recruited from the Nottingham area. Controls had no history of
neurological impairment and showed no symptoms of neglect assessed using the same battery of tests as that administered to patients. All
controls had intact hemifields and hearing performance within the normal range for their age (Davis, 1995). Visual stimuli consisted of two
geometric shapes: a red circle and a blue square. Each was closed and subtended 8.3 of visual angle. Auditory stimuli were two digitally
created vowel sounds: “ah” and “ee.” Vowel pairs were separated in their fundamental frequency by four semitones so that they could be
easily segregated from one another (Culling, Summerfield, & Marshall, 1994). Vowels were presented at 69 dB(A) on single-target trials and
at 66 dB(A) on dual-target trials to reduce the sound level cues that would otherwise distinguish single- from dual-target trials. Before
testing, each participant was familiarized with the visual and auditory stimuli to ensure they could accurately identify and discriminate
them. The apparatus (see Figure 1) consisted of five small Bose Cube loudspeakers arranged horizontally at ear level. Loudspeakers were
mounted on a flat metal frame (height 150 cm, width 150 cm) supported off the floor by two metal legs. Each loudspeaker was located at an
eccentricity of 0, 17, and 34 to either side of the fixation point, providing one position on the vertical midline, two in the left
hemispace, and two in the right. A sheet of white fabric was stretched across the metal frame to cover the loudspeakers and to prevent any
visual cues about their position. Participants sat in front of this screen at a viewing distance of 1,100 mm. Visual stimuli were projected
from a ceiling-mounted projector (NEC WT610) onto the screen at precisely the same positions as the loudspeakers. Visual targets were the
same size as the loudspeakers, and visual and auditory stimuli were presented at exactly the same location in extrapersonal space. A
fixation cross was projected immediately below the horizontal midline and remained on the screen throughout each trial. Stimulus
presentation was controlled using customized software running on a Viglen PC equipped with a standard graphics card and a Motu 24 I/O sound
card. Verbal responses were coded and entered into the computer by the experimenter. Schematic of the experimental apparatus. A projector,
screen, and speaker array were used to present visual and auditory stimuli to the same egocentric position. The display had five locations
equally distributed in the horizontal plane and centered on the participant's vertical midline. Visual and auditory stimuli were presented
in separate blocks. Patient information and clinical characteristics Note. F = female. M = male. L = left. R = right. aLine length = 172 mm;
bTotal number of targets = 27 L and 27 R. Ethical approval for the study was granted by the Nottingham committee of the National Health
Research Ethics Board, and written consent was obtained from all participants. Testing comprised the clinical assessment and the two
experimental tasks. Clinical assessments were carried out on the ward while experimental tasks were conducted in a sound-attenuated booth at
the Ear, Nose, and Throat department. For the patients, assessment and experimental tasks were carried out on consecutive days with
cancellation and visual confrontation tasks repeated on the final day of testing. Controls completed all of their testing within a single
session in the sound-attenuated booth. Visual and auditory versions of the extinction and TOJ tasks were presented in separate blocks, with
the order counterbalanced across participants. Once the participant was ready, trials were initiated by the experimenter and always started
with fixation. In the extinction task, stimuli were presented singly or in a pair for one second. Single-target trials comprised an equal
number of each stimulus (e.g., “ah” and “ee”). Dual-target trials always contained one of each stimulus (e.g., a blue square and a red
circle) and were always presented to locations separated by an angle of 34 (i.e., with one loudspeaker position between them). Single
targets were presented to each of the five horizontal locations. Dual targets were presented to three spatial configurations in which the
pair was (a) located in the right hemispace (RH), (b) across the central meridian (CM) or (c) located in the left hemispace (LH; Figure 2).
Stimulus type, location, and number of single- and dual-target trials (12 within each spatial configuration) were sampled with equal
probability in each task. Trials were presented in a random order. Participants were asked to report the number of targets (one or two), but
were not required to identify them. Responses were, therefore, orthogonal to the location of the stimuli in order to negate any confounds
associated with a spatially mediated response bias. In the TOJ task, the pair of targets (e.g., blue square and red circle) was always
presented at an eccentricity of 17 in the left and right hemifields (i.e., separated by a fixed angle of 34). The stimulus onset asynchrony
(SOA) between the two targets could take the following values: 1, 50, 100, 150, 200, 250, 300, and 400 ms. The side and order in which each
stimulus type was presented were counterbalanced. Six right- and six left-first target trials occurred at each location for all SOAs. This
method of constant stimuli provided a spread of data that was sufficient to plot individual psychometric functions. The offset of the pair
of targets was simultaneous, and the first stimulus was always presented for a total of one second. Both the SOA and the side on which the
target first appeared were randomized. Participants indicated verbally which of the two targets appeared first by reporting its identity.
Again, participants were required to report a stimulus attribute (identity) that was orthogonal to the location to which stimuli were
presented (Shore & Spence, 2005). To assess the effect of eccentricity, the proportion of correctly detected single-target trials was
entered into contingency tables for each participant. Trial outcome (0 = incorrect, 1 = correct) was entered as the dependent variable and
eccentricity (–34, −17, 0, 17, 34) as the independent variable. Due to the binary nature of the response, the data were analyzed using
Somers’ d. This is a test of association between the outcome (frequency of correct responses) and the ordinal independent variable
(eccentricity; see Siegel & Castellan, 1988). The left-hand panel illustrates the dual-target conditions in the extinction task. Dual
targets were presented to the left hemispace (LH), to the right hemispace (RH), and across the central meridian (CM). Single targets were
presented to each of the five locations. The visual angles correspond to the five locations at which stimuli were presented. The right-hand
panel presents a schematic of the temporal order judgment (TOJ) task. Two stimuli were always presented at a fixed eccentricity of 17.
Stimulus onset asynchronies (SOAs) varied between 0 and 400 ms. To evaluate the ability to detect dual targets compared to single targets,
the data were transformed into an extinction index derived from that of Duncan et al. (1999). An index was calculated separately for LH, CM,
and RH configurations by dividing the proportion of correct responses on dual-target trials (PD) by the product of the proportion of correct
responses for the single trials (PS) at the corresponding two locations: PD/ (PSleft × PSright); see Table 2. An index value equal to unity
represents equivalent performance on both singleand dual-target trials, whilst an index value of less than unity reflects relatively worse
performance on dual-target trials. To measure the degree of association between each patient's visual and auditory extinction indices,
stimulus modality only was permuted across all locations. Random permutations were repeated 1,000,000 times in order to estimate an
empirical distribution for any differences in the index under the null hypothesis. Reported p-values estimate the two-tailed probability
that there is no difference in the distribution of visual and auditory indices over the three spatial configurations. Randomization tests
were also used to compare the patients’ extinction indices with the observed indices for the control group. In this comparison the p-value
reflects the two-tailed probability that the patient's performance is consistent with that of the controls (see Figure 3). The number of
correctly named targets at each SOA was recoded to represent the proportion of “right-first” responses. These data were then analyzed using
a probit analysis (Finney, 1964), which produces a probability estimate for each participant of right-first responses as a linear function
of SOA, transformed via a cumulative standard normal distribution (McCullagh & Nelder, 1983). The resulting probability functions were then
used to estimate each participant's point of subjective simultaneity (PSS): the point at which right-first and left-first decisions are
equally probable (i.e., .5). PSS values deviating from zero reflect slowed responses for the ipsilesional (PSS > 0) or contralesional
stimulus (PSS < 0). Goodness-of-fit estimates (GoF) for the observed and estimated data for each individual were calculated using the
deviance statistic (p-values < .05 suggest that the psychometric function is a poor fit). For one case (J.B. auditory test), a single
incorrect response at SOA of 300 ms was omitted as an outlier on the basis that it was grossly inconsistent with performance at adjacent
SOAs and reduced the GoF. The deviance statistic and the 95% confidence intervals around the PSS were calculated using Matlab's “glmfit”
routine (Version 7.5.0; Math-Works Inc., 2007; see Collett, 2002, for a description). For each individual, the sharpness of temporal acuity
was also estimated using the just noticeable difference (JND). This is calculated as half of the SOA between the point on the probit
function at which 25% and 75% of targets were reported as right-first trials (Shore & Spence, 2005). Table 3 reports the statistics
associated with the individual probit analyses for each patient. Controls performed near ceiling on both extinction tasks, and there was no
significant effect of eccentricity (? = .05). For visual stimuli, mean target accuracy was 99% (SD = 0.9%) for single targets and 99% (SD =
0.6%) for dual targets. For auditory stimuli, mean accuracy was 99% (SD = 1.0%) for single targets and 99% (SD = 0.3%) for dual targets (see
Table 2). Mean extinction indices for stimuli at the LH, CM, and RH spatial configurations approached unity in the visual and auditory tasks
(see Figure 3, Panel 1A), demonstrating consistent performance between single- and dual-target trials. Proportion of trials correctly
identified as single- and dual-target displays and extinction indices Note. S = single-target display; D = dual-target display; EI =
extinction index. Single-target scores are reported across the two locations in each spatial configuration. Mean proportion correct scores
are reported for controls. LH = left hemispace, CM = central meridian, and RH = right hemispace. **.001 < p < .01; ***p < .001. Left-hand
column: mean extinction indices for the control group (Panel 1A, mean; error bars represent the 95% confidence interval, CI, around the
mean) and individual indices for each patient (Panels 2A and 3A), by stimulus location and modality. Right-hand column: mean probit
functions for the control group (Panel 1B, mean) and individual functions for patients (Panels 2B and 3B), by stimulus onset asynchrony
(SOA) and modality. TOJ statistics by modality for the control group and individual patients Note. TOJ = temporal order judgment. GoF =
goodness-of-fit. JND = just noticeable difference. PSS = point of subjective simultaneity. CI = confidence interval. JND, PSS, and 95% CI
for PSS are reported in ms. p-values associated with the GoF statistics indicate the probability that the difference between the observed
data and estimated functions is statistically significant. In the right-hand column the p-values indicate the probability that the PSS
estimate is equal to zero (PSS = 0). Results for the TOJ task also demonstrated near veridical judgments of temporal asynchrony. Panel 1B in
Figure 3 plots the mean probit function as a function of SOA for the visual and auditory stimuli. For comparison with the patients, the mean
PSS values for the control group along with the 95% confidence intervals (CIs) are presented in Table 3. In the visual modality, the mean
PSS was −13 ms (SD = 26 ms), and in the auditory modality it was 15 ms (SD = 44 ms). Neither PSS differed significantly from zero, t(14) =
−1.97, p = .07, and t(14) = 1.33, p = .20, respectively. The steep slope of the probit function indicates good temporal acuity with a visual
JND of 50 ms and an auditory JND of 59 ms. Table 2 shows that F.D.'s single-target performance in the extinction task was close to ceiling
at all three spatial configurations (mean = 97%). No effect of eccentricity upon performance was observed in either the visual or the
auditory modality (p > .1). In contrast, extinction indices of < 1 revealed a significant reduction in accuracy on dual- compared to single-
target trials on visual and auditory trials (Figure 3, Panel 3A). This pattern is consistent with extinction in dual-target trials. With the
exception of dual visual targets presented to the RH, F.D.'s performance was significantly worse than that of the controls at all locations
(p < .001), decreasing monotonically as the stimuli moved from the RH to the LH spatial configurations. Statistical comparisons of visual
and auditory extinction indices at each location revealed no difference (p = .15) indicating comparable rates of extinction in both
modalities. In the TOJ task, F.D. showed a general reduction of temporal acuity (Figure 3 Panel 3B). Goodness-of-fit for the observed data
and estimated function were acceptable (see Table 3). The estimated mean fell outside the 95% CI around the control mean. F.D.'s visual PSS
revealed a large bias away from the contralesional target. Visual targets presented on the left had to precede those on the right by an
estimated 335 ms before their onsets were judged to be simultaneous. In contrast there was no evidence for an auditory spatiotemporal bias,
with the auditory PSS close to that of the controls (14 ms). F.D.'s data, therefore, reveal a multimodal impairment in detecting
simultaneous visual or auditory stimuli in the extinction task and a dissociation between visual and auditory judgments of temporal order.
Importantly, this task by modality interaction occurs for stimuli presented to identical egocentric locations (i.e., 17). J.B.'s detection
accuracy for single targets in the extinction task was 100% (see Table 2). In the visual modality, extinction indices of unity demonstrated
equally good performance for single- and dual-target trials at all locations (Figure 3, Panel 4A). Auditory extinction indices for stimulus
pairs presented to LH and CM revealed a slight decrement in dual- compared to single-target detection rates at these locations. Although
responses to centrally presented auditory targets were reliably less accurate than those of controls (p < .05), visual and auditory
performance was statistically consistent at this location (p > .2). This patient, therefore, demonstrates no reliable difference in
performance across the two modalities. In the TOJ task, JND estimates in the visual (266 ms) and auditory (96 ms) tasks showed impoverished
temporal acuity compared to controls (Figure 3, Panel 4B). The probit function on the visual task was particularly shallow and had to be
extrapolated beyond the SOA range in order to estimate the PSS (–544 ms). In the auditory task, the deviation of the PSS from zero was much
smaller (–148 ms), but in the same direction (95% CIs around the visual and auditory PSS did not overlap revealing a reliable reduction in
auditory compared to visual spatiotemporal bias; see Table 3). Despite this, both visual and auditory PSS values fall outside the 95% CI
around the control mean, revealing a multimodal spatiotemporal bias towards the ipsilesional stimulus. J.B's data, therefore, reveal a
multimodal impairment of temporal order judgments for asynchronous visual and auditory stimuli in the absence of multimodal extinction for
the same objects when these are simultaneously presented. Research investigating the degree of correspondence between visual and auditory
attentional bias has produced mixed findings (e.g., De Renzi et al., 1989; Pavani et al., 2004; Pavani et al., 2003; Sinnett et al., 2007;
Soroker et al., 1997; Zimmer et al., 2003). Inconsistencies in estimates of the degree of association between visual and auditory neglect
and extinction may in part be due to methodological factors: first, the use of tests that each afford different measurement sensitivity in
each sensory modality, and, second, the grouping of data across individuals who vary in the site and extent of their causal lesion. The
current study addresses these methodological considerations by comparing visual and auditory neglect symptoms separately for two patients
using tests designed explicitly to match spatial and temporal stimulus parameters in each modality. Despite a common clinical diagnosis of
visual neglect using pen and paper tests, both patients showed a unique pattern of impairment across two laboratory tasks commonly used to
assess unimodal neglect and extinction. Our results reveal within-patient variability in the presence and degree of association between
visual and auditory inattention as well as highlighting task-dependent variability in the way these are expressed. In the extinction task,
F.D. showed reduced awareness of contralesional visual and auditory stimuli when a competing stimulus was present. This bias increased
across a leftward spatial gradient that is consistent with gradient models of neglect and extinction (Cate & Behrmann, 2002; Kinsbourne,
1993; Pouget & Driver, 2000). This suggests the balance of competition between stimuli with a fixed angle of separation is mediated by both
their relative and egocentric locations. The lack of any significant difference between extinction indices in each modality suggests that
performance in this patient was affected by a common gradient of inattention. This is consistent with a multimodal attentional impairment
for visual and auditory information represented within a common spatial metric (e.g., Frassinetti et al., 2002; Pavani et al., 2002, 2003).
F.D.'s TOJ data, in contrast, reveal intact auditory performance in the presence of a visual deficit. In the auditory TOJ, F.D. performed
within normal limits, although the shallow function indicated a general loss of temporal acuity. In the visual TOJ, F.D.'s data revealed a
large spatiotemporal bias against the contralesional object. This is consistent with prior entry models of neglect and extinction, which
attribute spatiotemporal deficits to a disruption in the competitive interactions between ipsi- and contralesional stimuli (Di Pellegrino et
al., 1997; Karnath et al., 2002; Rorden et al., 1997). F.D.'s data, therefore, reveal an association between visual and auditory deficits on
one task (extinction) and a clear dissociation between visual and auditory deficits on another (TOJ). Data for J.B. also reveal a
dissociation between the extinction and TOJ tasks. In this patient, intact performance on the visual and auditory extinction tasks contrasts
with a multimodal deficit in the TOJ for the same objects presented to the same location. The pattern of dissociations above caution against
the assumption that the same test presented in different modalities will tap identical attentional resources. Previous studies comparing
associations between visual and auditory attentional bias using extinction and TOJ tasks have found conflicting results (e.g., Eramudugolla
et al., 2007; Sinnett et al., 2007) and highlight the variability typically observed in comparisons of visual and auditory inattention using
different measures. The use of visual and auditory stimuli precisely matched in their spatial and temporal parameters in this study suggests
that this variation is attributable to the way individual patterns of impairment disrupt spatial and temporal selection in particular tasks
rather than to confounds associated with the presentation of stimuli in each modality to different (intracranial and extrapersonal)
locations (e.g., Sinnett et al., 2007). The strength of association between visual and auditory deficits in our patients depends upon
whether the presentation of stimuli is simultaneous or asynchronous. Recent evidence from transcranial magnetic stimulation studies has
revealed modality-specific substrates of visual and auditory time perception (Bueti, Bahrami, & Walsh, 2008). Spatial and temporal deficits
in neglect and extinction often coincide (Becchio & Berone, 2006; Danckert et al., 2007), and it is likely that associations between visual
and auditory deficits will reflect the contribution of these to task performance in each modality. In audition, temporal asynchronies have
been shown to be a powerful determinant of scene segregation. Common onsets provide a cue for grouping while asynchronous onsets promote
stimulus segregation (e.g., Hukin & Darwin, 1995). This temporal segregation is thought to occur prior to localization (Hill & Darwin, 1996;
Woods & Colburn, 1992) and would have provided a nonspatial mechanism for segregating sounds in the TOJ but not the extinction task. Asking
respondents to report the identity rather than the position of the first target in the TOJ task might have accentuated this nonspatial
effect, distinguishing our data from evidence of an ipsilesional bias in TOJ for auditory targets identified by their spatial location
(Eramudugolla et al., 2007; Karnath et al., 2002). Task-dependent variability in the effect of auditory spatial cues has previously been
reported by McDonald and Ward (1999) and has been interpreted as evidence for mechanisms of auditory attention that operate independently of
spatial location. This can be contrasted with the obligatory role of spatial information in delimiting object boundaries in the visual
system (Baylis & Driver, 1993; Kim & Cave, 2001; Kramer, Weber, & Watson, 1997; Lamy & Tsal, 2000) and provides a potential account for the
(relative and absolute) dissociation of visual and auditory TOJs in our patients. An important implication of this account is that the
assumption of equivalence that has informed much of the research investigating visual and auditory attentional biases inadequately describes
modality-specific variation in the contribution of spatial information to performance on measures of neglect and extinction. In conclusion,
the current results suggest that associations between visual and auditory attentional deficits can occur but these are neither obligatory
nor pervasive. Associations varied within patients and across tasks and were apparent despite the use of visual and auditory stimuli that
were precisely matched in their spatial and temporal parameters. An important implication of this result is that measures of association
between visual and auditory inattention will vary according to the type of task involved and the extent that performance in each modality is
mediated by spatial information. This argues against the characterization of attention as either a uni-modal or a supramodal resource and
instead supports a more complex model of task-specific impairment that may vary across modalities in neglect. Research has revealed both
unimodal and multimodal responses to spatial information across a distributed network of cortical areas (Bushara, Weeks, Ishii, Catalan, &
Tian, 1999; Lewis et al., 2000; Macaluso, Frith, & Driver, 2000), with neurons responding to spatially convergent input from different
modalities found in the superior temporal and intraparietal sulci as well as the prefrontal cortices (Beauchamp, 2005; Gifford & Cohen,
2004; Maier, Neu-hoff, Logothetis, & Ghazanfar, 2004). Neglect symptoms can arise from damage to many different cortical and subcortical
regions (Coulthard, Parton, & Husain, 2007; Halligan, Fink, Marshall, & Vallar, 2003; Vallar, 2001), and it is likely that individual
patterns of impairment will reflect the contribution of these to different levels of spatial description (Ghazanfar & Schroeder, 2006;
Karnath, 2001; Marshall, Halligan, & Robertson, 1993; Mesulam, 1981). Accordingly the type of deficit observed when this distributed system
is compromised will depend on the site and extent of the causal lesion as well as the nature of spatial representation required by the task.
By using matched tasks to explore the manifestation of these deficits across different sensory modalities, confounds associated with
different measures of performance can be reduced. This approach supplements evidence from existing investigations of neglect and extinction
in order to specify more precisely the way spatial selection operates across different sensory modalities and tasks.
