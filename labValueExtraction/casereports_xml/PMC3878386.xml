<?xml version="1.0" ?>
<!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd">
<pmc-articleset><article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Cortex</journal-id>
      <journal-id journal-id-type="iso-abbrev">Cortex</journal-id>
      <journal-title-group>
        <journal-title>Cortex; a Journal Devoted to the Study of the Nervous System and Behavior</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">0010-9452</issn>
      <issn pub-type="epub">1973-8102</issn>
      <publisher>
        <publisher-name>Masson</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">23664001</article-id>
      <article-id pub-id-type="pmc">3878386</article-id>
      <article-id pub-id-type="publisher-id">S0010-9452(13)00089-0</article-id>
      <article-id pub-id-type="doi">10.1016/j.cortex.2013.03.006</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Report</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Sight and sound out of synch: Fragmentation and renormalisation of audiovisual integration and subjective timing</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Freeman</surname>
            <given-names>Elliot D.</given-names>
          </name>
          <email>elliot.freeman@city.ac.uk</email>
          <xref rid="aff1" ref-type="aff">a</xref>
          <xref rid="cor1" ref-type="corresp">&#x2217;</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ipser</surname>
            <given-names>Alberta</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Palmbaha</surname>
            <given-names>Austra</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Paunoiu</surname>
            <given-names>Diana</given-names>
          </name>
          <xref rid="aff1" ref-type="aff">a</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Brown</surname>
            <given-names>Peter</given-names>
          </name>
          <xref rid="aff2" ref-type="aff">b</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Lambert</surname>
            <given-names>Christian</given-names>
          </name>
          <xref rid="aff3" ref-type="aff">c</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Leff</surname>
            <given-names>Alex</given-names>
          </name>
          <xref rid="aff4" ref-type="aff">d</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Driver</surname>
            <given-names>Jon</given-names>
          </name>
          <xref rid="aff4" ref-type="aff">d</xref>
        </contrib>
      </contrib-group>
      <aff id="aff1"><label>a</label>City University London, United Kingdom</aff>
      <aff id="aff2"><label>b</label>John Radcliffe Hospital, Oxford University, United Kingdom</aff>
      <aff id="aff3"><label>c</label>St George's, University of London, United Kingdom</aff>
      <aff id="aff4"><label>d</label>Institute of Cognitive Neuroscience, University College London, United Kingdom</aff>
      <author-notes>
        <corresp id="cor1"><label>&#x2217;</label><italic>Corresponding author</italic>. City University, Northampton Square, London EC1V 0HB, United Kingdom. <email>elliot.freeman@city.ac.uk</email></corresp>
      </author-notes>
      <pub-date pub-type="pmc-release">
        <day>1</day>
        <month>11</month>
        <year>2013</year>
      </pub-date>
      <!-- PMC Release delay is 0 months and 0 days and was based on <pub-date
						pub-type="ppub">.-->
      <pub-date pub-type="ppub">
        <month>11</month>
        <year>2013</year>
      </pub-date>
      <volume>49</volume>
      <issue>10</issue>
      <fpage>2875</fpage>
      <lpage>2887</lpage>
      <history>
        <date date-type="received">
          <day>19</day>
          <month>11</month>
          <year>2012</year>
        </date>
        <date date-type="rev-recd">
          <day>10</day>
          <month>2</month>
          <year>2013</year>
        </date>
        <date date-type="accepted">
          <day>19</day>
          <month>3</month>
          <year>2013</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>&#xA9; 2013 Elsevier Srl. All rights reserved.</copyright-statement>
        <copyright-year>2013</copyright-year>
        <copyright-holder>Elsevier Ltd</copyright-holder>
        <license xlink:href="https://creativecommons.org/licenses/by/3.0/">
          <license-p>Open Access under <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/3.0/">CC BY 3.0</ext-link> license</license-p>
        </license>
      </permissions>
      <abstract>
        <p>The sight and sound of a person speaking or a ball bouncing may seem simultaneous, but their corresponding neural signals are spread out over time as they arrive at different multisensory brain sites. How subjective timing relates to such neural timing remains a fundamental neuroscientific and philosophical puzzle. A dominant assumption is that temporal coherence is achieved by sensory resynchronisation or recalibration across asynchronous brain events. This assumption is easily confirmed by estimating subjective audiovisual timing for groups of subjects, which is on average similar across different measures and stimuli, and approximately veridical. But few studies have examined normal and pathological individual differences in such measures.</p>
        <p>Case PH, with lesions in pons and basal ganglia, hears people speak before seeing their lips move. Temporal order judgements (TOJs) confirmed this: voices had to <italic>lag</italic> lip-movements (by &#x223C;200&#xA0;msec) to seem synchronous to PH. Curiously, voices had to <italic>lead</italic> lips (also by &#x223C;200&#xA0;msec) to maximise the McGurk illusion (a measure of audiovisual speech integration). On average across these measures, PH's timing was therefore still veridical. Age-matched control participants showed similar discrepancies. Indeed, normal individual differences in TOJ and McGurk timing correlated <italic>negatively</italic>: subjects needing an auditory lag for subjective simultaneity needed an auditory lead for maximal McGurk, and vice versa. This generalised to the Stream&#x2013;Bounce illusion. Such surprising antagonism seems opposed to good sensory resynchronisation, yet average timing across tasks was still near-veridical.</p>
        <p>Our findings reveal remarkable disunity of audiovisual timing within and between subjects. To explain this we propose that the timing of audiovisual signals within different brain mechanisms is perceived relative to the average timing across mechanisms. Such renormalisation fully explains the curious antagonistic relationship between disparate timing estimates in PH and healthy participants, and how they can still perceive the timing of external events correctly, on average.</p>
      </abstract>
      <kwd-group>
        <title>Keywords</title>
        <kwd>Audiovisual integration</kwd>
        <kwd>Psychophysics</kwd>
        <kwd>Individual differences</kwd>
        <kwd>Illusions</kwd>
        <kwd>Sensory timing</kwd>
      </kwd-group>
    </article-meta>
    <notes>
      <p id="misc0010">Reviewed 21 December 2012. Action editor Robert McIntosh</p>
    </notes>
  </front>
  <body>
    <sec sec-type="intro" id="sec1">
      <label>1</label>
      <title>Introduction</title>
      <p>When a person speaks, we usually expect to hear their voice at the same time as seeing their lips move. Furthermore, if we watch their lips, it often helps us to hear their voice better, via &#x2018;speechreading&#x2019; (<xref rid="bib57" ref-type="bibr">Sumby and Pollack, 1954</xref>). Two distinct kinds of processes are implied by such observations: synchronisation and integration. Firstly, we are sensitive to when auditory and visual events are occurring at the same time (<xref rid="bib1" ref-type="bibr">Alais and Carlile, 2005</xref>; <xref rid="bib27" ref-type="bibr">King, 2005</xref>; <xref rid="bib29" ref-type="bibr">Kopinska and Harris, 2004</xref>; <xref rid="bib56" ref-type="bibr">Sugita and Suzuki, 2003</xref>). Secondly, the ability to benefit from the combination of modalities, as in speechreading, requires that auditory and visual information be brought together in the brain and integrated. So automatic and compelling is such integration that artificial mismatches between sound and vision can easily induce illusory changes in the perceived location, timing or actual interpretation of the stimuli (<xref rid="bib5" ref-type="bibr">Bertelson and Radeau, 1981</xref>; <xref rid="bib23" ref-type="bibr">Howard and Templeton, 1966</xref>; <xref rid="bib33" ref-type="bibr">McGurk and MacDonald, 1976</xref>; <xref rid="bib72" ref-type="bibr">Witkin et&#xA0;al., 1952</xref>).</p>
      <p>It is easy to take for granted that audiovisual events are always synchronised and integrated correctly. But here, we present the first ever confirmed case of a patient (PH) who hears peoples' voices <italic>before</italic> he sees their lips move. Testing this individual in comparison with neurologically healthy participants gave us the unique opportunity to address two issues: Firstly, we ask whether PH's auditory leading phenomenon is selective for subjective synchrony or whether his audiovisual integration is also affected. This addresses a current debate over whether optimal integration depends on achieving <italic>subjective</italic> synchrony, or whether integration obeys independent temporal constraints (<xref rid="bib3" ref-type="bibr">Arnold et&#xA0;al., 2005</xref>; <xref rid="bib32" ref-type="bibr">Martin et&#xA0;al., 2013</xref>; <xref rid="bib39" ref-type="bibr">Munhall et&#xA0;al., 1996</xref>; <xref rid="bib46 bib47" ref-type="bibr">Soto-Faraco and Alsius, 2007, 2009</xref>; <xref rid="bib62" ref-type="bibr">van Wassenhove et&#xA0;al., 2007</xref>). Secondly, PH's pathological desynchronisation might provide insight into the deeper question of how (or indeed whether) sensory synchronisation is normally achieved, which has long perplexed neuroscientists and philosophers (<xref rid="bib11" ref-type="bibr">Dennett and Kinsbourne, 1995</xref>; <xref rid="bib21" ref-type="bibr">Harris et&#xA0;al., 2008</xref>; <xref rid="bib26" ref-type="bibr">Keetels and Vroomen, 2012</xref>; <xref rid="bib51" ref-type="bibr">Spence and Squire, 2003</xref>; <xref rid="bib66" ref-type="bibr">Vroomen and Keetels, 2010</xref>; <xref rid="bib74" ref-type="bibr">Zeki and Bartels, 1998</xref>). We consider this issue first.</p>
      <sec id="sec1.1">
        <label>1.1</label>
        <title>Multisensory synchronisation</title>
        <p>The problem of synchronisation is exemplified by the maxim known as Segal's law: &#x2018;<italic>With one clock you always know the time; with two you are never sure</italic>&#x2019;. Does the brain also have multiple clocks, and if so, does this create a similar uncertainty? There are many multimodal convergence zones in the brain (<xref rid="bib7" ref-type="bibr">Bushara et&#xA0;al., 2001</xref>; <xref rid="bib8" ref-type="bibr">Cappe et&#xA0;al., 2009</xref>; <xref rid="bib12" ref-type="bibr">Driver and Noesselt, 2008</xref>; <xref rid="bib16" ref-type="bibr">Ghazanfar and Schroeder, 2006</xref>; <xref rid="bib31" ref-type="bibr">Macaluso and Driver, 2005</xref>; <xref rid="bib34" ref-type="bibr">Meredith et&#xA0;al., 1987</xref>; <xref rid="bib54" ref-type="bibr">Stevenson et&#xA0;al., 2010</xref>), and to get there, auditory and visual signals must traverse different routes and distances, thus most likely arriving at different times (<xref rid="bib2" ref-type="bibr">Arnold et&#xA0;al., 2001</xref>; <xref rid="bib4" ref-type="bibr">Aschersleben and Prinz, 1995</xref>; <xref rid="bib17" ref-type="bibr">Halliday and Mingay, 1964</xref>; <xref rid="bib38" ref-type="bibr">Moutoussis and Zeki, 1997</xref>; <xref rid="bib55" ref-type="bibr">Stone et&#xA0;al., 2001</xref>). Consequently each area will have different information about when visual and auditory events occurred (<xref rid="bib42" ref-type="bibr">Scharnowski et&#xA0;al., 2013</xref>). This entails a &#x2018;multiple-clocks&#x2019; uncertainty for knowing the absolute and relative timing of external events.</p>
        <p>Despite such systemic and intrinsic asynchrony, subjects still often recognise when auditory and visual sources are approximately synchronous (<xref rid="bib21" ref-type="bibr">Harris et&#xA0;al., 2008</xref>), at least for proximal if not always for distal stimuli (<xref rid="bib1" ref-type="bibr">Alais and Carlile, 2005</xref>; <xref rid="bib3" ref-type="bibr">Arnold et&#xA0;al., 2005</xref>; <xref rid="bib22" ref-type="bibr">Heron et&#xA0;al., 2007</xref>; <xref rid="bib27" ref-type="bibr">King, 2005</xref>; <xref rid="bib29" ref-type="bibr">Kopinska and Harris, 2004</xref>; <xref rid="bib55" ref-type="bibr">Stone et&#xA0;al., 2001</xref>; <xref rid="bib56" ref-type="bibr">Sugita and Suzuki, 2003</xref>; <xref rid="bib66" ref-type="bibr">Vroomen and Keetels, 2010</xref>). Shifts in subjective simultaneity following adaptation to asynchrony are consistent with the existence of mechanisms functioning at least locally to resynchronise temporal discrepancies between modalities (<xref rid="bib14" ref-type="bibr">Fujisaki et&#xA0;al., 2004</xref>; <xref rid="bib20" ref-type="bibr">Hanson et&#xA0;al., 2008</xref>; <xref rid="bib36" ref-type="bibr">Miyazaki et&#xA0;al., 2006</xref>; <xref rid="bib73" ref-type="bibr">Yamamoto et&#xA0;al., 2012</xref>). However, individuals differ widely with respect to the objective audiovisual asynchrony which they perceive as subjectively synchronous (the Point of Subjective Simultaneity &#x2013; PSS; <xref rid="bib55" ref-type="bibr">Stone et&#xA0;al., 2001</xref>). This may depend intrinsically on the time for neural conduction and processing of signals, which may differ between stimuli and individuals (<xref rid="bib2" ref-type="bibr">Arnold et&#xA0;al., 2001</xref>; <xref rid="bib4" ref-type="bibr">Aschersleben and Prinz, 1995</xref>; <xref rid="bib17" ref-type="bibr">Halliday and Mingay, 1964</xref>; <xref rid="bib38" ref-type="bibr">Moutoussis and Zeki, 1997</xref>; <xref rid="bib55" ref-type="bibr">Stone et&#xA0;al., 2001</xref>), though attentional biases may also account for some apparent individual differences in multisensory timing (<xref rid="bib49" ref-type="bibr">Spence and Parise, 2010</xref>; <xref rid="bib50" ref-type="bibr">Spence et&#xA0;al., 2001</xref>). Furthermore, even within the same subjects given the same stimuli, different tasks produce uncorrelated estimates of PSS (<xref rid="bib61" ref-type="bibr">van Eijk et&#xA0;al., 2008</xref>) though such variations may depend on strategic variables (<xref rid="bib15" ref-type="bibr">Garc&#xED;a-P&#xE9;rez and Alcal&#xE1;-Quintana, 2012</xref>; <xref rid="bib43" ref-type="bibr">Schneider and Bavelier, 2003</xref>; <xref rid="bib61" ref-type="bibr">van Eijk et&#xA0;al., 2008</xref>). Thus synchronising mechanisms, if they exist (<xref rid="bib74" ref-type="bibr">Zeki and Bartels, 1998</xref>), may not function perfectly.</p>
        <p>If there were a single specialised mechanism for multisensory synchronisation, one might expect to find individuals for whom different modalities have been chronically desynchronised following a brain trauma. Loss of acuity for temporal order has been observed following temporal lobectomy (<xref rid="bib45" ref-type="bibr">Sherwin and Efron, 1980</xref>), but the lack of selective impairments in temporal processing is inconsistent with the notion of a unitary specialised mechanism underlying timing perception (<xref rid="bib71" ref-type="bibr">Wiener et&#xA0;al., 2011</xref>). Indeed, there is only one previously reported case of apparently acquired sensory desynchronisation (<xref rid="bib19" ref-type="bibr">Hamilton et&#xA0;al., 2006</xref>). <xref rid="bib19" ref-type="bibr">Hamilton et&#xA0;al. (2006)</xref> described patient AWF who claimed to experience &#x2018;<italic>a perceived temporal mismatch</italic>&#x2019; (Abstract). However they did not specify whether vision actually preceded or lagged audition, and did not formally quantify the temporal mismatch using objective measures, for example by measuring performance across a range of audiovisual asynchronies. Thus to date, evidence that sensory synchronisation can be pathologically impaired rests largely on AWF's subjective report, which is not very specific.</p>
      </sec>
      <sec id="sec1.2">
        <label>1.2</label>
        <title>Dependence of integration on synchronisation</title>
        <p>While investigations of synchronisation have typically focused on temporal relationships between modalities (e.g., <xref rid="bib21" ref-type="bibr">Harris et&#xA0;al., 2008</xref>), the multiple-clocks problem also logically applies more generally between different processes. Here we consider two such notional processes, supporting subjective temporal judgements versus those that serve to integrate inputs from different modalities. We ask whether sound and vision are optimally integrated when they are subjectively synchronous. These processes are not logically the same, and evidence from functional brain imaging suggests they are supported by distinct brain mechanisms (<xref rid="bib6" ref-type="bibr">Bertini et&#xA0;al., 2010</xref>; <xref rid="bib35" ref-type="bibr">Miller and D'Esposito, 2005</xref>; <xref rid="bib54" ref-type="bibr">Stevenson et&#xA0;al., 2010</xref>). Given such separation, and the &#x2018;multiple-clocks&#x2019; problem which that entails, any evidence of dependence of integration on synchronisation could be indicative of synchronising mechanisms operating between distinct cognitive processes, not just between modalities as a whole.</p>
        <p>It seems intuitive that such <italic>unity</italic> of timing across processes should be achieved. Such an intuition might be based on the assumption that single physical events should be associated with a unitary percept (<xref rid="bib69" ref-type="bibr">Welch and Warren, 1980</xref>). It might indeed be surprising if we consciously perceived different aspects of the same event as occurring at different times (though in some cases it seems we do; <xref rid="bib2" ref-type="bibr">Arnold et&#xA0;al., 2001</xref>; <xref rid="bib38" ref-type="bibr">Moutoussis and Zeki, 1997</xref>). Evidence suggests that the brain does actively strive to maintain synchrony across processes. For example in the &#x2018;unity effect&#x2019;, stimuli which are readily integrated (such as meaningful speech sounds and lip-movements) tend to be judged as synchronous even if they are actually not (<xref rid="bib64" ref-type="bibr">Vatakis and Spence, 2007</xref>). Conversely, integration may depend on a prior decision about the temporal correspondence of auditory and visual streams. For example, in the classic McGurk illusion (<xref rid="bib33" ref-type="bibr">McGurk and MacDonald, 1976</xref>), the combination of a voice saying /ba/ and a face mouthing [ga] often results in hearing the syllable /da/, while auditory /da/ with visual [ba] can sound like /ba/, but such visual interference declines (on average) with increasing asynchrony between voice and lips (<xref rid="bib39" ref-type="bibr">Munhall et&#xA0;al., 1996</xref>; <xref rid="bib46 bib47" ref-type="bibr">Soto-Faraco and Alsius, 2007, 2009</xref>; <xref rid="bib62" ref-type="bibr">van Wassenhove et&#xA0;al., 2007</xref>). Similarly for non-speech stimuli, we are more likely (on average) to perceive two balls as bouncing off each other when their collision is accompanied simultaneously by a sound, compared to when these auditory and visual events are asynchronous (<xref rid="bib44" ref-type="bibr">Sekuler et&#xA0;al., 1997</xref>). Though such findings demonstrate dependence of integration on synchrony, on average across participants, its critical dependence on individuals' own subjective synchrony has not been examined to date.</p>
        <p>The above positive evidence suggests that the brain actively benefits from, and actively strives for subjective unity across its different process. But however desirable, a unitary percept may not always be achieved. Some observations appear to challenge the intuitive dependence of multisensory integration on audiovisual synchronisation (<xref rid="bib48" ref-type="bibr">Spence and Ngo, 2012</xref>). For example in the McGurk effect, <xref rid="bib46 bib47" ref-type="bibr">Soto-Faraco and Alsius (2007, 2009)</xref> used a dual-task paradigm to measure McGurk interference and subjective synchrony as a function of audiovisual asynchrony. They found that illusory McGurk percepts were often reported even for audiovisual stimuli that could be reliably identified as asynchronous (on average across participants). Such &#x2018;<italic>dual perception</italic>&#x2019; of good lip-voice integration despite a detectable audiovisual asynchrony hints that unity can be violated, and thus in principle measures of subjective integration and synchronisation might be based on their own stimulus inputs and correspondence mechanisms rather than shared or synchronised mechanisms. Some doubt remains about this however, because integration and synchronisation judgements still centred on similar near-veridical asynchronies (on average), and thus could still be subject to common synchronising mechanisms. Furthermore, any apparent differences between the measures might just reflect different criteria for deciding whether two asynchronous events from different modalities should be integrated or segmented, compared to when deciding whether the two events are synchronous or asynchronous. The mismatch between measures was also small, though note that these measures were averaged across observers, which might conceal the true extent to which optimal timing may differ between mechanisms within individuals.</p>
        <p>Neuropsychological studies might contribute to this debate if cases could be found where brain lesions result in selective impairment of either synchronisation or integration, or joint impairment of both together. A case of the latter kind seems to be reported by <xref rid="bib19" ref-type="bibr">Hamilton et&#xA0;al. (2006)</xref>, where the &#x2018;temporal mismatch&#x2019; experienced by patient AWF coincided with an eliminated McGurk effect for veridically synchronous stimuli. However Hamilton et&#xA0;al. did not test McGurk under different conditions of audiovisual asynchrony. Thus the critical evidence for true interdependence of synchronisation and integration functions was lacking, which would have been provided if the McGurk effect had been reinstated in AWF, for subjectively simultaneous stimuli.</p>
      </sec>
      <sec id="sec1.3">
        <label>1.3</label>
        <title>The present study</title>
        <p>From the above review it may be concluded that the question of how, or indeed whether, the brain can minimise discrepancies in timing between modalities and between cognitive processes, has not yet been satisfactorily resolved. Critical insights may be gained by studying individual differences between measures probing synchronisation and integration, and comparing natural variations in these measures with those acquired following brain injury.</p>
        <p>In particular, we can examine (1) whether PH is an example of a categorical breakdown of putative unifying mechanisms, or whether his lesions have merely shifted him along a continuum of disunity, where we may also find ourselves. We therefore ask, how unusual is PH (Experiment 1)? If highly abnormal, he could be &#x2018;the exception that proves the rule&#x2019;, that unity and synchrony are normally achieved in individuals (albeit with inaccuracies). But exceptions can also &#x2018;prove&#x2019; rules wrong. Our evidence, of large discrepancies between our two measures in PH and surprisingly also in normal subjects, suggests that asynchrony and disunity may rule instead.</p>
        <p>We can also ask (2) whether PH's acquired subjective asynchrony is specific to perception of audiovisual temporal order or whether this affects the temporal tuning of audiovisual integration, and also how closely measures of integration correspond with measures of synchrony, within normal individuals. We assess integration in the McGurk effect (Experiment 2) and the Stream&#x2013;Bounce illusion (Experiment 3). If multimodal integration and synchronisation of speech stimuli are based on dependent mechanisms, it seems straightforward to predict that individual differences for our two measures will correlate positively. Alternatively, a null correlation seems intuitively likely if these mechanisms were fully independent. We find neither. Our counterintuitive results call for a revised understanding of how the brain solves the multiple-clocks problem, which we propose.</p>
        <p>Our study simply replicated the dual-task paradigm of <xref rid="bib46" ref-type="bibr">Soto-Faraco and Alsius (2007)</xref> with PH and normal controls. On each trial, we presented brief movies with a range of audiovisual asynchronies. There then followed two tasks, temporal order judgement (TOJ) and phoneme discrimination, to obtain two concurrent measures of the audiovisual asynchrony that (1) is perceived as synchronous, and (2) induces maximal integration, as measured by the strength of the McGurk illusion. We then analysed individual differences on these measures rather than just average performance.</p>
        <p>As PH's phenomenology is of a distinct temporal order, of lips lagging voices, TOJ was chosen to probe his subjective report as directly as possible. We were also concerned that the alternative paradigm, Simultaneity Judgement, might be performed heuristically on the basis of the quality of speech integration, and thus our measure of subjective timing in PH and control subjects might have been confounded by changes in integration as a function of asynchrony.</p>
        <p>Before reporting the methods and results of our experiments we first provide detailed documentation of case PH.</p>
      </sec>
    </sec>
    <sec id="sec2">
      <label>2</label>
      <title>PH case study</title>
      <p>PH, a retired pilot aged 67, first experienced auditory leading while watching television. He initially suspected poor dubbing, but then later noticed the same phenomenon in conversations with people. After seeking medical advice at his workplace, he was referred to Professor Peter Brown at his Queen Square neurology clinic, where we recruited him for this research. He also reports perceiving the sound of his own voice before the proprioception of his corresponding mouth and jaw movements. The onset seems to have been abrupt, not accompanied by any other symptoms, and initially progressing slowly but now stable according to his subjective reports, though becoming temporarily more intense when fatigued. He also reported experiencing difficulty in speech comprehension in noisy environments, though attributes this to tinnitus. In November 2007 he had surgery to treat pericarditis, and in 2008 he had developed generalised myasthenia gravis [anti-acetylcholine (ACh) receptor antibody and electromyography (EMG) positive]. His current complaint came on 2&#x2013;3 months after the onset of the myasthenia, however it is unknown to what extent these phenomena are related (<xref rid="bib25" ref-type="bibr">Keesey, 1999</xref>).</p>
      <p>A routine neurological examination revealed no abnormalities. There was no evidence of fatiguability. Mild hearing loss for high frequencies was observed using audiometry. Performance in a standard battery of neuropsychological tests (<xref rid="tbl1" ref-type="table">Table 1</xref>) revealed generally high functioning with no specific functional impairments. He showed above average Wechsler intelligence quotient (IQ) (<xref rid="bib59" ref-type="bibr">The Psychological Corporation, 1999</xref>) and near-perfect performance on tests of everyday attention (<xref rid="bib41" ref-type="bibr">Robertson, 2006</xref>), and the Visual Object and Space Perception Battery (<xref rid="bib68" ref-type="bibr">Warrington and James, 1991</xref>), with the sole exception of silhouette identification (19/30). Sentence repetition (<xref rid="bib52" ref-type="bibr">Spreen and Benton, 1969</xref>), performed while the speaker's face was hidden from view, was perfect and immediate.</p>
      <sec id="sec2.1">
        <label>2.1</label>
        <title>Imaging</title>
        <p>High resolution magnetic resonance imaging (MRI) (500&#xA0;&#x3BC;m<sup>3</sup>) revealed two lesions. Lesion 1 was located in superior mesencephalon, at the left anterio-medial tip of the subthalamic nucleus (11.5&#xA0;mm left and 16.8&#xA0;mm posterior to the anterior commisure). Total lesion volume was 42&#xA0;mm<sup>3</sup>. Lesion 2 was located in mid-brainstem within the right dorso-medial pontine nucleus at the level of middle cerebellar peduncle around the exit of the trigeminal nerve (see <xref rid="fig1" ref-type="fig">Fig.&#xA0;1</xref>). These were considered likely to represent small established lacunar infarcts. There was no evidence of an acute ischaemic lesion or microhaemorrhages.</p>
        <p>Diffusion tensor imaging (DTI) was undertaken using images from healthy subjects, to identify brain regions which are connected to the lesion sites (see <xref rid="appsec1" ref-type="sec">Supplementary Methods S1 and Supplementary Figure&#xA0;1</xref>). Results indicated that lesion 1 had ipsilateral projections predominately into the motor cortico-striato-pallido-thalamic-cortical relay loop, and a small projection with the Orbito-Frontal relay loop. Cortical projections were consistent with Limbic subthalamic nucleus (STN) (<xref rid="bib30" ref-type="bibr">Lambert et&#xA0;al., 2012</xref>). Lesion 2 lay along the olivo-collicular pathway (<xref rid="appsec1" ref-type="sec">Supplementary Figure&#xA0;1</xref>), with largely ipsilateral projections to inferior colliculus and extending down to the medial territory of the peri-olivary nucleus. There was also a possible involvement of the tectopontine pathway. This second lesion may be associated with the early auditory system. Both regions have been implicated in crossmodal interactions (<xref rid="bib18" ref-type="bibr">Halverson and Freeman, 2010</xref>; <xref rid="bib28" ref-type="bibr">Kolomiets et&#xA0;al., 2001</xref>), and in event timing (<xref rid="bib58" ref-type="bibr">Teki et&#xA0;al., 2011</xref>).</p>
      </sec>
    </sec>
    <sec sec-type="methods" id="sec3">
      <label>3</label>
      <title>Methods</title>
      <sec id="sec3.1">
        <label>3.1</label>
        <title>Healthy participants</title>
        <p>Experiment 1 had 10 participants similar in age to PH (59&#x2013;74 years, mean 65, standard deviation &#x2013; SD 5). Experiment 2 had 27 neurologically healthy young subjects (18&#x2013;28 years, mean&#xA0;22), and included the results from the older age-matched controls. Data from four further participants were excluded, due to poor performance, resulting in implausible estimates of subjective timing &gt;300&#xA0;msec asynchrony, outside the typical range for multisensory integration (<xref rid="bib63" ref-type="bibr">Vatakis et&#xA0;al., 2008</xref>; <xref rid="bib64" ref-type="bibr">Vatakis and Spence, 2007</xref>) and indicative of poor quality data and unreliable function fits. Experiment 3 (testing the Stream&#x2013;Bounce illusion) had 24 participants aged 18&#x2013;24, excluding two others who reported no &#x2018;bounce&#x2019; illusion. All participants were na&#xEF;ve to the specific aims of this study. Participants received a monetary reward. Procedures were approved by the local Psychology ethics committee.</p>
      </sec>
      <sec id="sec3.2">
        <label>3.2</label>
        <title>Apparatus and stimuli</title>
        <p>Laboratory apparatus comprised an Apple Mac Mini, with Labtec&#xA0;speakers positioned either side of a 17" Sony HMD-A420 cathode ray tube (CRT) display, viewed in darkness from 70&#xA0;cm. Mobile apparatus for older participants and PH comprised a Sony Vaio SZ1XP PC with built-in speakers and 13.3" liquid crystal display (LCD) display, viewed from approximately 57&#xA0;cm. In both cases video mode was 1200&#xA0;&#xD7;&#xA0;800 with a 60&#xA0;Hz refresh rate. Subjects responded using the cursor keys on the standard keyboard.</p>
        <p>McGurk stimuli were based on <xref rid="bib46" ref-type="bibr">Soto-Faraco and Alsius (2007)</xref>, which were kindly provided by the authors (see <xref rid="fig2" ref-type="fig">Fig.&#xA0;2</xref> for dimensions, and <xref rid="mmc2 mmc3" ref-type="supplementary-material">Supplementary Video</xref>). Auditory /ba/ and /da/ phonemes (with white noise at 15% of maximum amplitude) were combined with visual lip-movements for [ba], [da] and [ga]. The two incongruent pairings for eliciting the McGurk effect were /ba/&#xA0;+&#xA0;[ga]&#xA0;=&#xA0;&#x2018;da&#x2019; and /da/&#xA0;+&#xA0;[ba]&#xA0;=&#xA0;&#x2018;ba&#x2019; or &#x2018;bda&#x2019;. The other two &#x2018;congruent&#x2019; pairings /ba/&#xA0;+&#xA0;[ba] and /da/&#xA0;+&#xA0;[da] tend to be heard correctly. Background was set to the average red green blue (RGB) value across all pixels and frames. For the Stream&#x2013;Bounce experiment, visual stimuli were two yellow circular at maximum contrast on a black background. Each moved from positions left and right above fixation, via the central fixation point, to opposite positions below fixation (see <xref rid="fig2" ref-type="fig">Fig.&#xA0;2</xref> for dimensions, and <xref rid="mmc2 mmc3" ref-type="supplementary-material">Supplementary Video</xref>). Animations were accompanied by a 400&#xA0;Hz tone of 100&#xA0;msec duration, with the same manipulation of asynchrony as for the McGurk stimuli. Movies were followed by 9&#xA0;pt white text prompting responses, displayed centrally.</p>
        <p>The following are the supplementary videos related to this article:<supplementary-material content-type="local-data" id="mmc2"><caption><title>Video 1</title><p>McGurk stimulus demo: Four combinations, played consecutively: 1. Auditory /ba/ with visual [ba]: congruent. 2. Auditory /ba/ with visual [ga] (incongruent: McGurk effect sounds like &#x201C;da&#x201D;). 3. Auditory /da/ with visual [ba] (incongruent: McGurk effect sounds like &#x201C;ba&#x201D;). 4. Auditory /da/ with visual [da]: congruent.</p></caption><media xlink:href="mmc2.jpg"/></supplementary-material><supplementary-material content-type="local-data" id="mmc3"><caption><title>Video 2</title><p>Stream&#x2013;bounce stimulus demo. Two examples, played consecutively: 1. Beep simultaneous with visual collision. 2. Beep lags visual collision by 150&#xA0;msec.</p></caption><media xlink:href="mmc3.jpg"/></supplementary-material></p>
        <p>We also tested PH with various biological and/or non-speech stimuli. Finger-click movies, of 3000&#xA0;msec duration, showed a hand with the middle finger clicking against the thumb. Sequences began with either the hand open (to provide predictive information) or closed. For scrambled-speech stimuli, the soundtrack from the original McGurk stimuli was passed through a three-channel noise vocoder using Praat software (version 5.1.21, <ext-link ext-link-type="uri" xlink:href="http://www.praat.org" id="intref0015">http://www.praat.org</ext-link>), rendering the speech unintelligible but without affecting the spectral composition of the sound or the temporal sequence of amplitude modulations. The video sequence remained the same. Non-biological stimuli comprised a white square (1.67&#xA0;&#xB0; on each side) on a black background, presented for 200&#xA0;msec and paired with a white-noise burst of 200&#xA0;msec duration.</p>
      </sec>
      <sec id="sec3.3">
        <label>3.3</label>
        <title>Design</title>
        <p>Except where specified we used a dual-task paradigm (<xref rid="bib46" ref-type="bibr">Soto-Faraco and Alsius, 2007</xref>) (<xref rid="fig2" ref-type="fig">Fig.&#xA0;2</xref>) to obtain two concurrent measures of the audiovisual asynchrony that is (1) perceived as synchronous, and (2) optimal for maximum audiovisual integration, as measured by the McGurk effect. All experiments employed a repeated-measures factorial design. For the audiovisual asynchrony manipulation, the soundtrack could be shifted forwards or backwards in time relative to the visual sequence over a range of &#xB1;500&#xA0;msec through nine equal steps of 125&#xA0;msec including zero (sound synchronous with video). In Experiments 1 and 2, an independent variable was the congruency of lip-movements with voice (see <xref rid="sec3.2" ref-type="sec">Stimuli</xref> above). There were two possible lip-voice combinations for each congruent/incongruent pairing. Only incongruous conditions were used for assessing McGurk interference. Two dependent measures were obtained from two responses elicited after each trial, for TOJs and phoneme identity/stream&#x2013;bounce judgements respectively.</p>
      </sec>
      <sec id="sec3.4">
        <label>3.4</label>
        <title>Procedure</title>
        <p>Each trial began with a fixation display. Following a keypress and a blank interval (duration randomly selected from the range 1000&#xA0;&#xB1;&#xA0;500&#xA0;msec), a movie was displayed for 2800&#xA0;msec. On each trial the audiovisual asynchrony and stimulus pairing were selected pseudo-randomly. Each stimulus pairing was presented at each of the nine possible asynchronies 8&#x2013;10 times in pseudorandom order. Following movie offset, there were two successive forced-choice questions. Firstly, a TOJ task&#xA0;asked whether the voice (or beep) onset preceded or followed the lip-movement (or visual collision). In Experiments 1 and 2, the second question elicited a phoneme discrimination, asking whether the voice said &#x201C;ba&#x201D; or &#x201C;da&#x201D; [a&#xA0;third option for &#x2018;other&#x2019;, used on only .3%&#xA0;&#xB1;&#xA0;.3% standard error of the mean (SEM) of trials, was not included in further analysis]. Subjects were encouraged to choose the option that sounded the closest to what they heard. In Experiment 3, this second question asked subjects to indicate whether they saw the balls bounce or stream through each other. The additional tests performed by PH, with finger-clicks, flashes and noise-bursts, and scrambled speech, were all run as a single-task eliciting TOJs.</p>
      </sec>
      <sec id="sec3.5">
        <label>3.5</label>
        <title>Analysis</title>
        <p>For TOJ, we plotted the proportion of &#x2018;voice second&#x2019; responses (where the auditory onset was judged to lag the visual onset) as a psychometric function of actual auditory lag time in milliseconds (note that negative lag denotes an auditory lead). The proportion of &#x2018;sound second&#x2019; values was typically below 50% for negative auditory lags (i.e., sound leads vision), and above 50% for positive auditory lags. A logistic function was then fitted to the psychometric data, using a maximum-likelihood algorithm provided by the PSIGNIFIT toolbox for Matlab (<xref rid="bib70" ref-type="bibr">Wichmann and Hill, 2001</xref>). We could then read off from the fitted function the critical auditory lag corresponding to the participant's PSS. This is the point at which the participant is at chance (50%) deciding whether the sound came first or second relative to the visual onset. The same software was used to find the slope of the function and to derive 95% confidence intervals for both PSS and slope estimates, via a bootstrapping procedure. Finally, we estimated the additional auditory lag required for the participant to go from responding at chance to responding &#x2018;voice second&#x2019; 75% of the time. The resulting value quantifies the lag that can produce a Just Noticeable Difference (JND) between subjectively synchronous and asynchronous stimuli.</p>
        <p>For the phoneme discrimination task we obtained the proportion of trials in which the reported phoneme was consistent with the lip-movements, averaged across incongruous conditions only. For example, a &#x2018;ba&#x2019; response to /da/&#xA0;+&#xA0;[ba] and a &#x2018;da&#x2019; response to /ba/&#xA0;+&#xA0;[ga] were scored as &#x2018;consistent&#x2019;. This was plotted as a psychometric function of auditory lag. The data from each of the two incongruent conditions, plus the average across them, were fit using an asymmetric double sigmoid function (ADS, following van Wassenhove et al., 2007), which results in a bell-shaped curve with adjustable height, width and asymmetry, using the following equation:<disp-formula id="ufd1"><mml:math id="M1" altimg="si1.gif" overflow="scroll"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>tanh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x2212;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x2212;</mml:mo><mml:mi>tanh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x2212;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mspace width="0.5em"/><mml:mtext>with</mml:mtext><mml:mspace width="0.25em"/><mml:mtext>constraints</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="0.25em"/><mml:mtext>and</mml:mtext><mml:mspace width="0.25em"/><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></disp-formula></p>
        <p>The optimal auditory lag for maximum McGurk interference (tMcG) from vision was read off at the peak of each of these interpolated functions and averaged, with 95% confidence intervals derived from fits of 1000 bootstrapped samples. For stream&#x2013;bounce judgements, ADS functions were fitted to the proportion of &#x2018;bounce&#x2019; responses.</p>
        <p>Across subjects, mean (and SD) of <italic>R</italic><sup>2</sup> values for goodness of fit of functions to the psychometric data were .89 (.13) for the TOJ task, and .75 (.18) for the phoneme discrimination task.</p>
      </sec>
    </sec>
    <sec sec-type="results" id="sec4">
      <label>4</label>
      <title>Results</title>
      <p>All inferential statistics reported in the following are based on parametric statistics, as data did not deviate significantly from normality (Kolmogorov&#x2013;Smirnov <italic>p</italic>&#xA0;&gt;&#xA0;.05).</p>
      <sec id="sec4.1">
        <label>4.1</label>
        <title>Experiment 1</title>
        <sec id="sec4.1.1">
          <label>4.1.1</label>
          <title>PH</title>
          <p>PH's TOJs corroborated his subjective report of voice leading lips. His PSS&#xA0;was shifted away from veridical to 210&#xA0;msec auditory lag. This means that subjective synchrony could only be restored for PH by artificially lagging voices relative to lip-movements (by 210&#xA0;msec, see <xref rid="tbl2" ref-type="table">Table 2</xref>), at which point temporal order became indistinguishable (<xref rid="fig3" ref-type="fig">Fig.&#xA0;3</xref>a). Also very curiously, the optimal asynchrony for maximum McGurk (tMcG)&#xA0;showed almost exactly the opposite asynchrony (240&#xA0;msec auditory lead was required for optimum McGurk). Thus voices effectively lagged lip-movements for the purposes of audiovisual speech integration (<xref rid="fig3" ref-type="fig">Fig.&#xA0;3</xref>b).</p>
          <p>To investigate the generality of PH's auditory lead we tested him on a variety of biological and artificial non-speech stimuli, using single-task TOJs. In separate single-task tests, we found PSS was closer to veridical for artificial stimuli (flash/noise-burst pairs: 2&#xA0;&#xB1;&#xA0;99&#xA0;msec auditory lag, 95% confidence interval), finger-clicks (with no significant difference between movies beginning from open or closed-hand positions: 64&#xA0;&#xB1;&#xA0;85&#xA0;msec), and for unintelligible noise-vocoded speech (52&#xA0;&#xB1;&#xA0;98&#xA0;msec). In contrast, a similar single-task paradigm with the original speech stimuli showed a similar PSS shift as in the dual-task situation (210&#xA0;&#xB1;&#xA0;90&#xA0;msec). It may therefore be concluded that PH's PSS shift was specific to speech, and not dependent on the number of concurrent tasks.</p>
        </sec>
        <sec id="sec4.1.2">
          <label>4.1.2</label>
          <title>Comparison with controls</title>
          <p>How unusual is PH? Using a modified <italic>t</italic> test for comparing an individual's test score with a small normative sample (<xref rid="bib10" ref-type="bibr">Crawford and Howell, 1998</xref>), we found PH's tMcG was significantly greater than for 10 healthy age-matched participants [Crawford <italic>t</italic>(9)&#xA0;=&#xA0;2.23, <italic>p</italic>&#xA0;=&#xA0;.05]. The discrepancy between PH's PSS and tMcG measures was also significantly greater than for the control sample [Crawford <italic>t</italic>(9)&#xA0;=&#xA0;2.46, <italic>p</italic>&#xA0;=&#xA0;.04]. On these measures PH therefore does seem abnormal. However his PSS was not significantly deviant from controls [<italic>t</italic>(9)&#xA0;=&#xA0;1.50, <italic>p</italic>&#xA0;=&#xA0;.17 ] (<xref rid="tbl2" ref-type="table">Table 2</xref>). <xref rid="fig3" ref-type="fig">Fig.&#xA0;3</xref> illustrates these results graphically as psychometric functions for PH compared with the group average function.</p>
          <p>We repeated the analysis after collecting data from a further sample of 27 young participants (see <xref rid="sec4.2" ref-type="sec">Expt. 2</xref>) with similar results (<xref rid="tbl2" ref-type="table">Table 2</xref>). Relative to the tMcG measure, PH was again significantly deviant from young participants [<italic>t</italic>(25)&#xA0;=&#xA0;2.64, <italic>p</italic>&#xA0;=&#xA0;.01], and from the whole combined-age sample [<italic>t</italic>(35)&#xA0;=&#xA0;2.55, <italic>p</italic>&#xA0;=&#xA0;.02]. The discrepancy between PSS and tMcG measures was also significant for the young [<italic>t</italic>(25)&#xA0;=&#xA0;2.14, <italic>p</italic>&#xA0;=&#xA0;.04] and combined-age sample [<italic>t</italic>(35)&#xA0;=&#xA0;2.25, <italic>p</italic>&#xA0;=&#xA0;.03]. However, he was not deviant relative to the PSS for young [<italic>t</italic>(25)&#xA0;=&#xA0;1.28, <italic>p</italic>&#xA0;=&#xA0;.21] and the combined-age sample [<italic>t</italic>(35)&#xA0;=&#xA0;1.37, <italic>p</italic>&#xA0;=&#xA0;.18].</p>
          <p>It is surprising to note that on the measure that reflects PH's subjective report of voice leading lips, some healthy participants showed PSS values of comparable magnitude to PH (<xref rid="fig4" ref-type="fig">Fig.&#xA0;4</xref>a). Given that some normal participants seemed to show a similar magnitude of PSS shift, is PH is the only one aware of asynchrony? 10/37 participants consistently reported a visual or auditory lead on more than 75% of synchronous trials. Thus for these participants, the difference between veridically synchronous stimuli and their personal PSS was actually greater than their JND for perceiving asynchrony. In other words, these subjects seemed to reliably perceive physically synchronous stimuli as asynchronous, at least under laboratory conditions.</p>
        </sec>
      </sec>
      <sec id="sec4.2">
        <label>4.2</label>
        <title>Experiment 2: McGurk with normative sample</title>
        <p>PH's two lesions in pons and STN seem well placed to disrupt audition and/or timing (<xref rid="bib18" ref-type="bibr">Halverson and Freeman, 2010</xref>; <xref rid="bib28" ref-type="bibr">Kolomiets et&#xA0;al., 2001</xref>; <xref rid="bib58" ref-type="bibr">Teki et&#xA0;al., 2011</xref>), and might explain the auditory lagging observed in tMcG. But how could the same lesions also produce an opposite shift in PSS, and PH's corresponding experience of auditory leading?</p>
        <p>It may be instructive to note that in PH our two measures of sensory timing are distributed roughly symmetrically around zero auditory lag. Thus despite the temporal disparity between mechanisms it seems that on average across measures he can still achieve near-veridical timing (see <xref rid="sec5" ref-type="sec">General discussion</xref> for further elaboration). It is suggested that in order to maintain veridical performance, and thus continue to live in the &#x2018;present moment&#x2019;, pathological auditory slowing within impaired mechanisms is balanced by perceiving auditory timing in preserved mechanisms as slightly earlier than veridical. In other words the asynchronies obtained within each mechanism might have been renormalised relative to the average asynchrony across mechanisms.</p>
        <p>Such renormalisation might explain how veridical perception is maintained on average following pathological disruption of timing in selected mechanisms, but for neurologically healthy people the prediction is highly counterintuitive: individual differences (<xref rid="bib55" ref-type="bibr">Stone et&#xA0;al., 2001</xref>) which bias one measure of subjective timing in one direction (e.g., auditory lead for PSS) might be associated with the opposite bias in other measures (e.g., auditory lag for tMcG, or vice versa). This prediction of a negative correlation contrasts with the positive correlation predicted if synchronising mechanisms brought individual differences in PSS (<xref rid="bib55" ref-type="bibr">Stone et&#xA0;al., 2001</xref>) and tMcG into agreement (<xref rid="bib14" ref-type="bibr">Fujisaki et&#xA0;al., 2004</xref>; <xref rid="bib21" ref-type="bibr">Harris et&#xA0;al., 2008</xref>; <xref rid="bib51" ref-type="bibr">Spence and Squire, 2003</xref>; <xref rid="bib66" ref-type="bibr">Vroomen and Keetels, 2010</xref>).</p>
        <p>To test this we measured the correlation between PSS and tMcG, across the whole sample of young and older participants (total <italic>N</italic>&#xA0;=&#xA0;37). As predicted by the compensation hypothesis above, the correlation was significantly negative (<italic>N</italic>&#xA0;=&#xA0;38, Pearson's <italic>&#x3C1;</italic>&#xA0;=&#xA0;&#x2212;.47, <italic>p</italic>&#xA0;=&#xA0;.003, <xref rid="fig4" ref-type="fig">Fig.&#xA0;4</xref>a). Yet on average performance on both measures remained near-veridical (<xref rid="fig3" ref-type="fig">Fig.&#xA0;3</xref>).</p>
      </sec>
      <sec id="sec4.3">
        <label>4.3</label>
        <title>Experiment 3: Stream&#x2013;Bounce</title>
        <p>Is this apparent repulsion of timing measures just a speech-specific phenomenon? We tested this with the Stream&#x2013;Bounce illusion (<xref rid="bib44" ref-type="bibr">Sekuler et&#xA0;al., 1997</xref>, <xref rid="fig1" ref-type="fig">Fig.&#xA0;1</xref>), in which two approaching &#x2018;balls&#x2019; may appear to bounce off each other when their collision coincides with a sound, rather than streaming past each other. As before, there were two questions after each trial. The first probed the temporal order of the sound relative to the visual collision. The second required participants to judge whether they saw the balls bouncing off each other or streaming through each other, from which we estimated the asynchrony for maximum &#x2018;bounce&#x2019; (tBounce). We again found a negative correlation between PSS and tBounce (Pearson's <italic>&#x3C1;</italic>&#xA0;=&#xA0;&#x2212;.54, <italic>p</italic>&#xA0;=&#xA0;.001, for 24 new young participants, <xref rid="fig4" ref-type="fig">Fig.&#xA0;4</xref>b). Note that in contrast to the McGurk illusion for speech where vision influences hearing, in this non-speech illusion, hearing influences vision. Thus we may infer that this negative correlation pattern, replicated for speech and non-speech, and in both directions of audiovisual influence, reflects a general (rather than a stimulus-specific or task-specific) characteristic of perception.</p>
      </sec>
    </sec>
    <sec id="sec5">
      <label>5</label>
      <title>General discussion</title>
      <p>Our psychophysical investigation of PH confirmed his subjective report of lips lagging voices, when measured using TOJ,&#xA0;but revealed the opposite bias for McGurk integration, with temporal tuning favouring auditory lagging. Thus PH suffers not only from an acquired disruption of synchronisation, but also a violation of perceptual unity of timing across different aspects of the same pairing of auditory and visual stimuli. Neurologically normal individuals also showed a comparable opponency between our two measures (in speech and non-speech and in both directions of audiovisual influence): thus if one subject showed auditory lagging for TOJ, the McGurk measure tended to show auditory leading (or vice versa). Altogether, these counterintuitive findings suggest that perception of synchrony and integration depend on distinct rather than common synchronising mechanisms, and reveal one strategy by which the brain might achieve near-veridical perception of the timing of multisensory events, at least on average, despite the evident temporal disunity of sensory processing.</p>
      <sec id="sec5.1">
        <label>5.1</label>
        <title>How unusual is PH?</title>
        <p>If specialised mechanisms existed to synchronise senses in normal brains, one would expect to find more cases of acquired sensory desynchronisation when such mechanisms are lesioned (<xref rid="bib71" ref-type="bibr">Wiener et&#xA0;al., 2011</xref>). There has only been one previous report, of patient AWF (<xref rid="bib19" ref-type="bibr">Hamilton et&#xA0;al., 2006</xref>). However the similarity with PH is difficult to assess, as the direction of AWF's acquired &#x2018;temporal mismatch&#x2019; was not specified, and he was only tested with synchronous stimuli. AWF showed no McGurk effect while PH did when tested with asynchronous (auditory leading) stimuli. AWF's lesions are also in a quite different location, in right parietal cortex, while PH's lesions are in mid-brain and brainstem. We can at least claim that the present case is the first to be reported of an acquired subjective auditory lead, which is speech-specific and accompanied by an auditory lag for optimal McGurk integration.</p>
        <p>Surprisingly, some healthy participants also showed large deviations of PSS; indeed for some, synchronous stimuli were just-noticeably asynchronous. Thus it seems PH is not so unusual in terms of experiencing a mismatch in audiovisual timing. Such ubiquitous sensory asynchrony further undermines support for the existence of specialised synchronisation mechanisms. It also raises the obvious question of why only PH is aware of his asynchrony in his everyday life. It is possible that our TOJ results from normal participants are specific to our laboratory conditions. In the outside world we learn to expect that when auditory and visual events originate from the same source, they are also very likely to occur simultaneously, regardless of their sensory timing. Under this unity assumption (<xref rid="bib64" ref-type="bibr">Vatakis and Spence, 2007</xref>; <xref rid="bib69" ref-type="bibr">Welch and Warren, 1980</xref>) our perception might tend to rely more on this expectation than any sensory evidence of asynchrony. Our paradigm, by contrast, presented a randomised range of asynchronous stimuli with no feedback about which was actually synchronous. In this situation the unity assumption cannot be confidently applied, and perceptions may rely more on asynchronous sensory inputs than prior expectations. Under such conditions even neurologically healthy subjects might notice an asynchrony given actually synchronous stimuli. As for PH, his subjective asynchrony (which changed unexpectedly later in life) might just be too great for him to reconcile with the assumption of unity, even outside the lab (<xref rid="bib64" ref-type="bibr">Vatakis and Spence, 2007</xref>; <xref rid="bib69" ref-type="bibr">Welch and Warren, 1980</xref>).</p>
        <p>While PH's auditory lead for PSS is not statistically abnormal, his auditory lag for optimal McGurk (tMcG) is. This might be explained if the principle impairment caused by his lesions is actually a slowing of auditory processing, consistent with the location of his lesion on a tract connecting with the inferior colliculus, part of the early auditory system (see <xref rid="appsec1" ref-type="sec">Supplementary Materials</xref> for an analysis of tractography).</p>
        <p>The dissociation between PH's temporal tuning of subjective simultaneity for TOJ, versus for phoneme discrimination, suggests that each different task may probe different mechanisms, each subject to their own neural asynchronies (<xref rid="bib4" ref-type="bibr">Aschersleben and Prinz, 1995</xref>). For example, one mechanism might be involved in speech integration and the other in judging sensory synchrony (<xref rid="bib9" ref-type="bibr">Calvert, 2001</xref>; <xref rid="bib35" ref-type="bibr">Miller and D'Esposito, 2005</xref>; <xref rid="bib67" ref-type="bibr">Vroomen and Stekelenburg, 2011</xref>). The further dissociation between PSS for speech versus non-speech would be consistent with the existence of special mechanisms for these different stimulus types (<xref rid="bib63" ref-type="bibr">Vatakis et&#xA0;al., 2008</xref>). Alternatively the same mechanisms might have different temporal tunings depending on the low-level characteristics of the specific stimulus presented (<xref rid="bib67" ref-type="bibr">Vroomen and Stekelenburg, 2011</xref>). From these dissociations it seems, at least for PH, that there are indeed multiple clocks (see <xref rid="sec1" ref-type="sec">Introduction</xref>), whose discrepant timings cannot be reconciled.</p>
      </sec>
      <sec id="sec5.2">
        <label>5.2</label>
        <title>How closely do measures of integration normally correspond with measures of synchrony?</title>
        <p>An appealing intuition is that single physical events should be associated with a unitary percept (<xref rid="bib69" ref-type="bibr">Welch and Warren, 1980</xref>). Evidence suggests that the brain strives for (<xref rid="bib64" ref-type="bibr">Vatakis and Spence, 2007</xref>), and benefits from (<xref rid="bib46 bib47" ref-type="bibr">Soto-Faraco and Alsius, 2007, 2009</xref>; <xref rid="bib62" ref-type="bibr">van Wassenhove et&#xA0;al., 2007</xref>) such unity. But PH shows a dramatic failure of unity, with voices subjectively leading lip-movements, at the same time as effectively lagging lip-movements for the purposes of integration. Is PH just an exception to the putative rule that unity is normally achieved? Previous studies with normal participants (using the original paradigm borrowed here) have also reported &#x2018;dual perception&#x2019; of good lip-voice integration despite a detectable audiovisual asynchrony (<xref rid="bib46" ref-type="bibr">Soto-Faraco and Alsius, 2007</xref>). However such violations were small when measured on average across participants, and could arguably have reflected different decision criteria for the two concurrent judgements. The TOJ task may be particularly susceptible to response biases (<xref rid="bib15" ref-type="bibr">Garc&#xED;a-P&#xE9;rez and Alcal&#xE1;-Quintana, 2012</xref>; <xref rid="bib47" ref-type="bibr">Soto-Faraco and Alsius, 2009</xref>; <xref rid="bib61" ref-type="bibr">van&#xA0;Eijk et&#xA0;al., 2008</xref>). However such criterion or response bias effects, or attentional biases such as prior-entry (<xref rid="bib49" ref-type="bibr">Spence and Parise, 2010</xref>; <xref rid="bib50" ref-type="bibr">Spence et&#xA0;al., 2001</xref>) cannot easily explain away the negative correlation we show in <xref rid="fig4" ref-type="fig">Fig.&#xA0;4</xref> (see our <xref rid="appsec1" ref-type="sec">Supplementary Discussion</xref>). Our analysis of individual differences reveals the true extent to which subjective unity is routinely violated in normal participants, who can sometimes perceive, concurrently, different aspects of a single pair of auditory and visual events to be occurring at quite different times relative to each other.</p>
      </sec>
      <sec id="sec5.3">
        <label>5.3</label>
        <title>Theoretical accounts</title>
        <p>Over the years there have been a variety of approaches to the problem of how temporal unity can be maintained across asynchronous processes in the brain (<xref rid="bib26" ref-type="bibr">Keetels and Vroomen, 2012</xref>). One solution might be to have dedicated mechanisms for timing events, via a supramodal mechanism (<xref rid="bib20" ref-type="bibr">Hanson et&#xA0;al., 2008</xref>; <xref rid="bib60" ref-type="bibr">Treisman, 1963</xref>), or specialised timing mechanisms residing in cerebellum or basal ganglia (<xref rid="bib24" ref-type="bibr">Ivry and Spencer, 2004</xref>), functioning to provide a common time code for multisensory events. Timing discrepancies might also be minimised (<xref rid="bib26" ref-type="bibr">Keetels and Vroomen, 2012</xref>), via temporal ventriloquism (<xref rid="bib13" ref-type="bibr">Freeman and Driver, 2008</xref>; <xref rid="bib37" ref-type="bibr">Morein-Zamir et&#xA0;al., 2003</xref>; <xref rid="bib65" ref-type="bibr">Vroomen and De Gelder, 2004</xref>), or by selectively delaying one modality (<xref rid="bib53" ref-type="bibr">Sternberg and Knoll, 1973</xref>), or by recalibration of temporal codes (<xref rid="bib14" ref-type="bibr">Fujisaki et&#xA0;al., 2004</xref>), so that a frequently occurring neural asynchrony is perceived as synchronous. Compensatory adjustments might also be made in a context-sensitive way, for example taking into account the distance of events from the observer (<xref rid="bib21" ref-type="bibr">Harris et&#xA0;al., 2008</xref>) or the prior likelihood that the causal events are actually synchronous or not (<xref rid="bib36" ref-type="bibr">Miyazaki et&#xA0;al., 2006</xref>; <xref rid="bib73" ref-type="bibr">Yamamoto et&#xA0;al., 2012</xref>).</p>
        <p>The above accounts, on first sight, seem difficult to square with the present evidence of disunity, and particularly the negative correlation between different measures of audiovisual timing (<xref rid="fig4" ref-type="fig">Fig.&#xA0;4</xref>). Our results suggest that timing discrepancies between mechanisms serving performance of our synchronisation and integration tasks cannot be fully reconciled. However, as we explain below (and in <xref rid="fig5" ref-type="fig">Fig.&#xA0;5</xref>), our evidence is still consistent with the mainstream assumption that the brain adjusts for differences in neural timing between distinct modalities. Our account just makes explicit the assumption that this adjustment is made based on <italic>average</italic> differences in timing: either between modalities (<xref rid="bib21" ref-type="bibr">Harris et&#xA0;al., 2008</xref>), or in principle more generally between cognitive processes or any arbitrary groupings of temporally discrepant mechanisms.</p>
      </sec>
      <sec id="sec5.4">
        <label>5.4</label>
        <title>Temporal renormalisation</title>
        <p>Given the present evidence that disparities in timing for different tasks cannot be fully minimised, there appears to be no escape from the multiple-clocks problem: &#x2018;<italic>with one clock you always know the time; with two you are never sure</italic>&#x2019;. But of course, Segal's maxim is misleading. Given a room full of clocks, each independently subject to inaccuracies, our best guess at the correct time comes from the average across all clocks. Thus statistically, the more clocks we have the better for accurately estimating this average. Such averaging may be how the brain solves the multiple-clocks problem. This problem is that different auditory and visual stimuli are processed at different speeds, and arrive at different mechanisms (e.g., contributing to synchrony and integration judgements respectively) at different times, resulting in a distribution of neural timings measured across the different mechanisms. From the point of view of an individual mechanism contributing to this distribution, it is uncertain to what extent the timing of its inputs reflects the true external timing of events or just internal processing delays (<xref rid="bib42" ref-type="bibr">Scharnowski et&#xA0;al., 2013</xref>). But the average over the distribution provides a purer estimate of the neural&#xA0;timing that relates most reliably to the true timing of external events (see <xref rid="fig5" ref-type="fig">Fig.&#xA0;5</xref> for a schematic illustration, and <xref rid="appsec1" ref-type="sec">Supplementary Discussion</xref> of how this could apply before and/or after unimodal signals). We propose that <italic>discrepancies in timing between mechanisms are not minimised but perceived relative to their average timing</italic>.</p>
        <p>In contrast to the other theoretical alternatives, this temporal renormalisation theory provides a fuller and more explicit account of all of our paradoxical findings: why a lesion produces opposite lags in different measures; why in normal participants different measures of subjective timing appear mutually repulsive, and how despite such disunity perception remains near-veridical <italic>on average across measures</italic>. To see how these phenomena emerge, note that in the multiple-clocks analogy, if one clock is particularly slow then this will bias the average, relative to which even the correct clocks will seem to be fast. In the brain, the mean neural delay of each sensory modality could also be attracted to particularly slow (or fast) neural events such that even events with relatively normal timing may be perceived as slightly fast (or slow). In PH, the integrative mechanisms probed by the McGurk task may have an unusually delayed auditory input, due to a selective brain lesion. The central tendency of the distribution will shift towards auditory lags, and relative to this, auditory signals from other unaffected mechanisms, such as those performing TOJ, will now be perceived to be leading. Yet on average across these measures, and despite pathological disruptions of timing, performance remains near-veridical. Renormalisation also explains the negative correlation we observed in healthy individuals, for whom auditory and visual timing may vary naturally in a similar (or opposite) direction to PH: in different people the greater the deviation in the auditory lead (lag) direction for some mechanisms, the more auditory leading (lagging) will be reported for other mechanisms, relative to the mean asynchrony, thus resulting in an <italic>apparent</italic> antagonism between mechanisms. Given that the mean neural asynchrony most reliably relates to external synchrony (under the&#xA0;unity assumption), renormalisation explains how near-veridical performance is maintained on average, across mechanisms and also across subjects.</p>
      </sec>
      <sec id="sec5.5">
        <label>5.5</label>
        <title>Simulation</title>
        <p>Computations based on statistical distributions are routinely proposed in Bayesian theories of perception (<xref rid="bib36" ref-type="bibr">Miyazaki et&#xA0;al., 2006</xref>; <xref rid="bib73" ref-type="bibr">Yamamoto et&#xA0;al., 2012</xref>), while functions similar to averaging over such distributions have been considered in theories of population coding (<xref rid="bib40" ref-type="bibr">Roach et&#xA0;al., 2011</xref>). Assuming similar mechanisms in principle, we performed a simple simulation, in which we plotted values sampled from two random variables (&#x2018;clocks&#x2019;), after subtracting each from the average across a population of clocks. We found that this simple renormalisation model could accurately simulate the negative correlation observed (see <xref rid="appsec1" ref-type="sec">Supplementary Methods S2 and Supplementary Figure&#xA0;2</xref> for further details). This serves to demonstrate how the observed negative correlation phenomenon might emerge simply as a consequence of renormalisation, and <italic>not</italic> due to any explicit antagonism between mechanisms.</p>
      </sec>
      <sec sec-type="conclusions" id="sec5.6">
        <label>5.6</label>
        <title>Conclusions</title>
        <p>Neuroscientists and philosophers have long pondered the relationship between subjective and neural timing (<xref rid="bib11" ref-type="bibr">Dennett and Kinsbourne, 1995</xref>; <xref rid="bib21" ref-type="bibr">Harris et&#xA0;al., 2008</xref>; <xref rid="bib51" ref-type="bibr">Spence and Squire, 2003</xref>; <xref rid="bib74" ref-type="bibr">Zeki and Bartels, 1998</xref>). Our observations with PH and with neurologically healthy participants confirm that perception is characterised fundamentally by asynchrony and disunity: different aspects of the same pair of multisensory stimuli may be perceived with different asynchronies, and these discrepancies cannot be fully minimised. But an apparent antagonism between complementary measures of subjective timing reveals a superordinate principle, by which discrepant timings in the brain may nevertheless be renormalised to their average neural timing. By relating subjective timing to average neural timing, temporal renormalisation explains (1) why after a lesion PH experiences auditory leading in one task but the opposite auditory lead in another, (2) why different timing measures are negatively correlated across normal individuals, and (3) how the brain might tell the time from multiple clocks, with near-veridical accuracy, without needing resynchronising mechanisms.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="bib1">
        <element-citation publication-type="journal" id="sref1">
          <person-group person-group-type="author">
            <name>
              <surname>Alais</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Carlile</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Synchronizing to real events: Subjective audiovisual alignment scales with perceived auditory depth and speed of sound</article-title>
          <source>Proceedings of the National Academy of Sciences of the United States of America</source>
          <volume>102</volume>
          <issue>6</issue>
          <year>2005</year>
          <fpage>2244</fpage>
          <lpage>2247</lpage>
          <pub-id pub-id-type="pmid">15668388</pub-id>
        </element-citation>
      </ref>
      <ref id="bib2">
        <element-citation publication-type="journal" id="sref2">
          <person-group person-group-type="author">
            <name>
              <surname>Arnold</surname>
              <given-names>D.H.</given-names>
            </name>
            <name>
              <surname>Clifford</surname>
              <given-names>C.W.</given-names>
            </name>
            <name>
              <surname>Wenderoth</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Asynchronous processing in vision: Color leads motion</article-title>
          <source>Current Biology</source>
          <volume>11</volume>
          <issue>8</issue>
          <year>2001</year>
          <fpage>596</fpage>
          <lpage>600</lpage>
          <pub-id pub-id-type="pmid">11369204</pub-id>
        </element-citation>
      </ref>
      <ref id="bib3">
        <element-citation publication-type="journal" id="sref3">
          <person-group person-group-type="author">
            <name>
              <surname>Arnold</surname>
              <given-names>D.H.</given-names>
            </name>
            <name>
              <surname>Johnston</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Nishida</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Timing sight and sound</article-title>
          <source>Vision Research</source>
          <volume>45</volume>
          <issue>10</issue>
          <year>2005</year>
          <fpage>1275</fpage>
          <lpage>1284</lpage>
          <pub-id pub-id-type="pmid">15733960</pub-id>
        </element-citation>
      </ref>
      <ref id="bib4">
        <element-citation publication-type="journal" id="sref4">
          <person-group person-group-type="author">
            <name>
              <surname>Aschersleben</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Prinz</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Synchronizing actions with events: The role of sensory information</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>57</volume>
          <issue>3</issue>
          <year>1995</year>
          <fpage>305</fpage>
          <lpage>317</lpage>
          <pub-id pub-id-type="pmid">7770322</pub-id>
        </element-citation>
      </ref>
      <ref id="bib5">
        <element-citation publication-type="journal" id="sref5">
          <person-group person-group-type="author">
            <name>
              <surname>Bertelson</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Radeau</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Cross-modal bias and perceptual fusion with auditory&#x2013;visual spatial discordance</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>29</volume>
          <issue>6</issue>
          <year>1981</year>
          <fpage>578</fpage>
          <lpage>584</lpage>
          <pub-id pub-id-type="pmid">7279586</pub-id>
        </element-citation>
      </ref>
      <ref id="bib6">
        <element-citation publication-type="journal" id="sref6">
          <person-group person-group-type="author">
            <name>
              <surname>Bertini</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Leo</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Avenanti</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>L&#xE0;davas</surname>
              <given-names>E.</given-names>
            </name>
          </person-group>
          <article-title>Independent mechanisms for ventriloquism and multisensory integration as revealed by theta-burst stimulation</article-title>
          <source>The European Journal of Neuroscience</source>
          <volume>31</volume>
          <issue>10</issue>
          <year>2010</year>
          <fpage>1791</fpage>
          <lpage>1799</lpage>
          <pub-id pub-id-type="pmid">20584183</pub-id>
        </element-citation>
      </ref>
      <ref id="bib7">
        <element-citation publication-type="journal" id="sref7">
          <person-group person-group-type="author">
            <name>
              <surname>Bushara</surname>
              <given-names>K.O.</given-names>
            </name>
            <name>
              <surname>Grafman</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Hallett</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Neural correlates of auditory&#x2013;visual stimulus onset asynchrony detection</article-title>
          <source>The Journal of Neuroscience</source>
          <volume>21</volume>
          <issue>1</issue>
          <year>2001</year>
          <fpage>300</fpage>
          <lpage>304</lpage>
          <pub-id pub-id-type="pmid">11150347</pub-id>
        </element-citation>
      </ref>
      <ref id="bib8">
        <element-citation publication-type="journal" id="sref8">
          <person-group person-group-type="author">
            <name>
              <surname>Cappe</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Rouiller</surname>
              <given-names>E.M.</given-names>
            </name>
            <name>
              <surname>Barone</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Multisensory anatomical pathways</article-title>
          <source>Hearing Research</source>
          <volume>258</volume>
          <issue>1&#x2013;2</issue>
          <year>2009</year>
          <fpage>28</fpage>
          <lpage>36</lpage>
          <pub-id pub-id-type="pmid">19410641</pub-id>
        </element-citation>
      </ref>
      <ref id="bib9">
        <element-citation publication-type="journal" id="sref9">
          <person-group person-group-type="author">
            <name>
              <surname>Calvert</surname>
              <given-names>G.A.</given-names>
            </name>
          </person-group>
          <article-title>Crossmodal processing in the human brain: Insights from functional neuroimaging studies</article-title>
          <source>Cerebral Cortex</source>
          <volume>11</volume>
          <issue>12</issue>
          <year>2001</year>
          <fpage>1110</fpage>
          <lpage>1123</lpage>
          <pub-id pub-id-type="pmid">11709482</pub-id>
        </element-citation>
      </ref>
      <ref id="bib10">
        <element-citation publication-type="journal" id="sref10">
          <person-group person-group-type="author">
            <name>
              <surname>Crawford</surname>
              <given-names>J.R.</given-names>
            </name>
            <name>
              <surname>Howell</surname>
              <given-names>D.C.</given-names>
            </name>
          </person-group>
          <article-title>Comparing an individual's test score against norms derived from small samples</article-title>
          <source>The Clinical Neuropsychologist</source>
          <volume>12</volume>
          <issue>4</issue>
          <year>1998</year>
          <fpage>482</fpage>
          <lpage>486</lpage>
        </element-citation>
      </ref>
      <ref id="bib11">
        <element-citation publication-type="journal" id="sref11">
          <person-group person-group-type="author">
            <name>
              <surname>Dennett</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Kinsbourne</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Time and the observer: The where and when of consciousness in the brain</article-title>
          <source>Behavioral and Brain Sciences</source>
          <volume>15</volume>
          <issue>1992</issue>
          <year>1995</year>
          <fpage>1</fpage>
          <lpage>35</lpage>
        </element-citation>
      </ref>
      <ref id="bib12">
        <element-citation publication-type="journal" id="sref12">
          <person-group person-group-type="author">
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Noesselt</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Multisensory interplay reveals crossmodal influences on &#x201C;sensory-specific&#x201D; brain regions, neural responses, and judgments</article-title>
          <source>Neuron</source>
          <volume>57</volume>
          <issue>1</issue>
          <year>2008</year>
          <fpage>11</fpage>
          <lpage>23</lpage>
          <pub-id pub-id-type="pmid">18184561</pub-id>
        </element-citation>
      </ref>
      <ref id="bib13">
        <element-citation publication-type="journal" id="sref13">
          <person-group person-group-type="author">
            <name>
              <surname>Freeman</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Direction of visual apparent motion driven solely by timing of a static sound</article-title>
          <source>Current Biology</source>
          <volume>18</volume>
          <issue>16</issue>
          <year>2008</year>
          <fpage>1262</fpage>
          <lpage>1266</lpage>
          <pub-id pub-id-type="pmid">18718760</pub-id>
        </element-citation>
      </ref>
      <ref id="bib14">
        <element-citation publication-type="journal" id="sref14">
          <person-group person-group-type="author">
            <name>
              <surname>Fujisaki</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Shimojo</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kashino</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Nishida</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Recalibration of audiovisual simultaneity</article-title>
          <source>Nature Neuroscience</source>
          <volume>7</volume>
          <issue>7</issue>
          <year>2004</year>
          <fpage>773</fpage>
          <lpage>778</lpage>
          <pub-id pub-id-type="pmid">15195098</pub-id>
        </element-citation>
      </ref>
      <ref id="bib15">
        <element-citation publication-type="journal" id="sref15">
          <person-group person-group-type="author">
            <name>
              <surname>Garc&#xED;a-P&#xE9;rez</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Alcal&#xE1;-Quintana</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>On the discrepant results in synchrony judgment and temporal-order judgment tasks: A quantitative model</article-title>
          <source>Psychonomic Bulletin &amp; Review</source>
          <volume>19</volume>
          <issue>5</issue>
          <year>2012</year>
          <fpage>820</fpage>
          <lpage>846</lpage>
          <pub-id pub-id-type="pmid">22829342</pub-id>
        </element-citation>
      </ref>
      <ref id="bib16">
        <element-citation publication-type="journal" id="sref16">
          <person-group person-group-type="author">
            <name>
              <surname>Ghazanfar</surname>
              <given-names>A.A.</given-names>
            </name>
            <name>
              <surname>Schroeder</surname>
              <given-names>C.E.</given-names>
            </name>
          </person-group>
          <article-title>Is neocortex essentially multisensory?</article-title>
          <source>Trends in Cognitive Sciences</source>
          <volume>10</volume>
          <issue>6</issue>
          <year>2006</year>
          <fpage>278</fpage>
          <lpage>285</lpage>
          <pub-id pub-id-type="pmid">16713325</pub-id>
        </element-citation>
      </ref>
      <ref id="bib17">
        <element-citation publication-type="journal" id="sref17">
          <person-group person-group-type="author">
            <name>
              <surname>Halliday</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Mingay</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>On the resolution of small time intervals and the effect of conduction delays on the judgement of simultaneity</article-title>
          <source>Quarterly Journal of Experimental Psychology</source>
          <volume>16</volume>
          <issue>1</issue>
          <year>1964</year>
          <fpage>37</fpage>
          <lpage>41</lpage>
        </element-citation>
      </ref>
      <ref id="bib18">
        <element-citation publication-type="journal" id="sref18">
          <person-group person-group-type="author">
            <name>
              <surname>Halverson</surname>
              <given-names>H.E.</given-names>
            </name>
            <name>
              <surname>Freeman</surname>
              <given-names>J.H.</given-names>
            </name>
          </person-group>
          <article-title>Medial auditory thalamic input to the lateral pontine nuclei is necessary for auditory eyeblink conditioning</article-title>
          <source>Neurobiology of Learning and Memory</source>
          <volume>93</volume>
          <issue>1</issue>
          <year>2010</year>
          <fpage>92</fpage>
          <lpage>98</lpage>
          <pub-id pub-id-type="pmid">19706335</pub-id>
        </element-citation>
      </ref>
      <ref id="bib19">
        <element-citation publication-type="journal" id="sref19">
          <person-group person-group-type="author">
            <name>
              <surname>Hamilton</surname>
              <given-names>R.H.</given-names>
            </name>
            <name>
              <surname>Shenton</surname>
              <given-names>J.T.</given-names>
            </name>
            <name>
              <surname>Coslett</surname>
              <given-names>H.B.</given-names>
            </name>
          </person-group>
          <article-title>An acquired deficit of audiovisual speech processing</article-title>
          <source>Brain and Language</source>
          <volume>98</volume>
          <issue>1</issue>
          <year>2006</year>
          <fpage>66</fpage>
          <lpage>73</lpage>
          <pub-id pub-id-type="pmid">16600357</pub-id>
        </element-citation>
      </ref>
      <ref id="bib20">
        <element-citation publication-type="journal" id="sref20">
          <person-group person-group-type="author">
            <name>
              <surname>Hanson</surname>
              <given-names>J.V.M.</given-names>
            </name>
            <name>
              <surname>Heron</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Whitaker</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Recalibration of perceived time across sensory modalities</article-title>
          <source>Experimental Brain Research</source>
          <volume>185</volume>
          <issue>2</issue>
          <year>2008</year>
          <fpage>347</fpage>
          <lpage>352</lpage>
          <pub-id pub-id-type="pmid">18236035</pub-id>
        </element-citation>
      </ref>
      <ref id="bib21">
        <element-citation publication-type="book" id="sref21">
          <person-group person-group-type="author">
            <name>
              <surname>Harris</surname>
              <given-names>L.R.</given-names>
            </name>
            <name>
              <surname>Harrar</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Jaekl</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Kopinska</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <chapter-title>Mechanisms of simultaneity constancy</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Nijhawan</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <source>Issues of Space and Time in Perception and Action</source>
          <year>2008</year>
          <publisher-name>Cambridge University Press</publisher-name>
          <fpage>232</fpage>
          <lpage>253</lpage>
        </element-citation>
      </ref>
      <ref id="bib22">
        <element-citation publication-type="journal" id="sref22">
          <person-group person-group-type="author">
            <name>
              <surname>Heron</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>McGraw</surname>
              <given-names>P.V.</given-names>
            </name>
            <name>
              <surname>Horoshenkov</surname>
              <given-names>K.V.</given-names>
            </name>
          </person-group>
          <article-title>Adaptation minimizes distance-related audiovisual delays</article-title>
          <source>Journal of Vision</source>
          <volume>7</volume>
          <issue>13</issue>
          <year>2007</year>
          <fpage>1</fpage>
          <lpage>8</lpage>
          <pub-id pub-id-type="pmid">17997633</pub-id>
        </element-citation>
      </ref>
      <ref id="bib23">
        <element-citation publication-type="book" id="sref23">
          <person-group person-group-type="author">
            <name>
              <surname>Howard</surname>
              <given-names>I.P.</given-names>
            </name>
            <name>
              <surname>Templeton</surname>
              <given-names>W.B.</given-names>
            </name>
          </person-group>
          <chapter-title>Human Spatial Orientation</chapter-title>
          <year>1966</year>
          <publisher-name>John Wiley &amp; Sons</publisher-name>
          <publisher-loc>Oxford</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib24">
        <element-citation publication-type="journal" id="sref24">
          <person-group person-group-type="author">
            <name>
              <surname>Ivry</surname>
              <given-names>R.B.</given-names>
            </name>
            <name>
              <surname>Spencer</surname>
              <given-names>R.M.C.</given-names>
            </name>
          </person-group>
          <article-title>The neural representation of time</article-title>
          <source>Current Opinion in Neurobiology</source>
          <volume>14</volume>
          <issue>2</issue>
          <year>2004</year>
          <fpage>225</fpage>
          <lpage>232</lpage>
          <pub-id pub-id-type="pmid">15082329</pub-id>
        </element-citation>
      </ref>
      <ref id="bib25">
        <element-citation publication-type="journal" id="sref25">
          <person-group person-group-type="author">
            <name>
              <surname>Keesey</surname>
              <given-names>J.C.</given-names>
            </name>
          </person-group>
          <article-title>Does myasthenia gravis affect the brain?</article-title>
          <source>Journal of the Neurological Sciences</source>
          <volume>170</volume>
          <issue>2</issue>
          <year>1999</year>
          <fpage>77</fpage>
          <lpage>89</lpage>
          <pub-id pub-id-type="pmid">10561522</pub-id>
        </element-citation>
      </ref>
      <ref id="bib26">
        <element-citation publication-type="book" id="sref26">
          <person-group person-group-type="author">
            <name>
              <surname>Keetels</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Vroomen</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <chapter-title>Perception of synchrony between the senses</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Murray</surname>
              <given-names>M.M.</given-names>
            </name>
            <name>
              <surname>Wallace</surname>
              <given-names>M.T.</given-names>
            </name>
          </person-group>
          <source>The Neural Bases of Multisensory Processes</source>
          <year>2012</year>
          <publisher-name>CRC Press</publisher-name>
          <publisher-loc>Boca Raton (FL)</publisher-loc>
          <fpage>1</fpage>
          <lpage>27</lpage>
        </element-citation>
      </ref>
      <ref id="bib27">
        <element-citation publication-type="journal" id="sref27">
          <person-group person-group-type="author">
            <name>
              <surname>King</surname>
              <given-names>A.J.</given-names>
            </name>
          </person-group>
          <article-title>Multisensory integration: Strategies for synchronization</article-title>
          <source>Current Biology</source>
          <volume>15</volume>
          <issue>9</issue>
          <year>2005</year>
          <fpage>R336</fpage>
          <lpage>R339</lpage>
          <pub-id pub-id-type="pmid">15886091</pub-id>
        </element-citation>
      </ref>
      <ref id="bib28">
        <element-citation publication-type="journal" id="sref28">
          <person-group person-group-type="author">
            <name>
              <surname>Kolomiets</surname>
              <given-names>B.P.</given-names>
            </name>
            <name>
              <surname>Deniau</surname>
              <given-names>J.M.</given-names>
            </name>
            <name>
              <surname>Mailly</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Menetrey</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Glowinski</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Thierry</surname>
              <given-names>A.M.</given-names>
            </name>
          </person-group>
          <article-title>Segregation and convergence of information flow through the cortico-subthalamic pathways</article-title>
          <source>The Journal of Neuroscience</source>
          <volume>21</volume>
          <issue>15</issue>
          <year>2001</year>
          <fpage>5764</fpage>
          <lpage>5772</lpage>
          <pub-id pub-id-type="pmid">11466448</pub-id>
        </element-citation>
      </ref>
      <ref id="bib29">
        <element-citation publication-type="journal" id="sref29">
          <person-group person-group-type="author">
            <name>
              <surname>Kopinska</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Harris</surname>
              <given-names>L.R.</given-names>
            </name>
          </person-group>
          <article-title>Simultaneity constancy</article-title>
          <source>Perception</source>
          <volume>33</volume>
          <issue>9</issue>
          <year>2004</year>
          <fpage>1049</fpage>
          <lpage>1060</lpage>
          <pub-id pub-id-type="pmid">15560507</pub-id>
        </element-citation>
      </ref>
      <ref id="bib30">
        <element-citation publication-type="journal" id="sref30">
          <person-group person-group-type="author">
            <name>
              <surname>Lambert</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Zrinzo</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Nagy</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Lutti</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Hariz</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Foltynie</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Confirmation of functional zones within the human subthalamic nucleus: Patterns of connectivity and sub-parcellation using diffusion weighted imaging</article-title>
          <source>NeuroImage</source>
          <volume>60</volume>
          <issue>1</issue>
          <year>2012</year>
          <fpage>83</fpage>
          <lpage>94</lpage>
          <pub-id pub-id-type="pmid">22173294</pub-id>
        </element-citation>
      </ref>
      <ref id="bib31">
        <element-citation publication-type="journal" id="sref31">
          <person-group person-group-type="author">
            <name>
              <surname>Macaluso</surname>
              <given-names>E.</given-names>
            </name>
            <name>
              <surname>Driver</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Multisensory spatial interactions: A window onto functional integration in the human brain</article-title>
          <source>Trends in Neurosciences</source>
          <volume>28</volume>
          <issue>5</issue>
          <year>2005</year>
          <fpage>264</fpage>
          <lpage>271</lpage>
          <pub-id pub-id-type="pmid">15866201</pub-id>
        </element-citation>
      </ref>
      <ref id="bib32">
        <element-citation publication-type="journal" id="sref32">
          <person-group person-group-type="author">
            <name>
              <surname>Martin</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Giersch</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Huron</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Van Wassenhove</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Temporal event structure and timing in schizophrenia: Preserved binding in a longer &#x201C;now&#x201D;</article-title>
          <source>Neuropsychologia</source>
          <volume>51</volume>
          <issue>2</issue>
          <year>2013</year>
          <fpage>358</fpage>
          <lpage>371</lpage>
          <pub-id pub-id-type="pmid">22813430</pub-id>
        </element-citation>
      </ref>
      <ref id="bib33">
        <element-citation publication-type="journal" id="sref33">
          <person-group person-group-type="author">
            <name>
              <surname>McGurk</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>MacDonald</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Hearing lips and seeing voices</article-title>
          <source>Nature</source>
          <volume>264</volume>
          <issue>5588</issue>
          <year>1976</year>
          <fpage>746</fpage>
          <lpage>748</lpage>
          <pub-id pub-id-type="pmid">1012311</pub-id>
        </element-citation>
      </ref>
      <ref id="bib34">
        <element-citation publication-type="journal" id="sref34">
          <person-group person-group-type="author">
            <name>
              <surname>Meredith</surname>
              <given-names>M.A.</given-names>
            </name>
            <name>
              <surname>Nemitz</surname>
              <given-names>J.W.</given-names>
            </name>
            <name>
              <surname>Stein</surname>
              <given-names>B.E.</given-names>
            </name>
          </person-group>
          <article-title>Determinants of multisensory integration in superior colliculus neurons. I. Temporal factors</article-title>
          <source>The Journal of Neuroscience</source>
          <volume>7</volume>
          <issue>10</issue>
          <year>1987</year>
          <fpage>3215</fpage>
          <lpage>3229</lpage>
          <pub-id pub-id-type="pmid">3668625</pub-id>
        </element-citation>
      </ref>
      <ref id="bib35">
        <element-citation publication-type="journal" id="sref35">
          <person-group person-group-type="author">
            <name>
              <surname>Miller</surname>
              <given-names>L.M.</given-names>
            </name>
            <name>
              <surname>D'Esposito</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Perceptual fusion and stimulus coincidence in the cross-modal integration of speech</article-title>
          <source>The Journal of Neuroscience</source>
          <volume>25</volume>
          <issue>25</issue>
          <year>2005</year>
          <fpage>5884</fpage>
          <lpage>5893</lpage>
          <pub-id pub-id-type="pmid">15976077</pub-id>
        </element-citation>
      </ref>
      <ref id="bib36">
        <element-citation publication-type="journal" id="sref36">
          <person-group person-group-type="author">
            <name>
              <surname>Miyazaki</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Yamamoto</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Uchida</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kitazawa</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian calibration of simultaneity in tactile temporal order judgment</article-title>
          <source>Nature Neuroscience</source>
          <volume>9</volume>
          <issue>7</issue>
          <year>2006</year>
          <fpage>875</fpage>
          <lpage>877</lpage>
          <pub-id pub-id-type="pmid">16732276</pub-id>
        </element-citation>
      </ref>
      <ref id="bib37">
        <element-citation publication-type="journal" id="sref37">
          <person-group person-group-type="author">
            <name>
              <surname>Morein-Zamir</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Soto-Faraco</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kingstone</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Auditory capture of vision: Examining temporal ventriloquism</article-title>
          <source>Cognitive Brain Research</source>
          <volume>17</volume>
          <issue>1</issue>
          <year>2003</year>
          <fpage>154</fpage>
          <lpage>163</lpage>
          <pub-id pub-id-type="pmid">12763201</pub-id>
        </element-citation>
      </ref>
      <ref id="bib38">
        <element-citation publication-type="journal" id="sref38">
          <person-group person-group-type="author">
            <name>
              <surname>Moutoussis</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zeki</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>A direct demonstration of perceptual asynchrony in vision</article-title>
          <source>Proceedings of the Royal Society B: Biological Sciences</source>
          <volume>264</volume>
          <issue>1380</issue>
          <year>1997</year>
          <fpage>393</fpage>
          <lpage>399</lpage>
          <pub-id pub-id-type="pmid">9107055</pub-id>
        </element-citation>
      </ref>
      <ref id="bib39">
        <element-citation publication-type="journal" id="sref39">
          <person-group person-group-type="author">
            <name>
              <surname>Munhall</surname>
              <given-names>K.G.</given-names>
            </name>
            <name>
              <surname>Gribble</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Sacco</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Ward</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Temporal constraints on the McGurk effect</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>58</volume>
          <issue>3</issue>
          <year>1996</year>
          <fpage>351</fpage>
          <lpage>362</lpage>
          <pub-id pub-id-type="pmid">8935896</pub-id>
        </element-citation>
      </ref>
      <ref id="bib40">
        <element-citation publication-type="journal" id="sref40">
          <person-group person-group-type="author">
            <name>
              <surname>Roach</surname>
              <given-names>N.W.</given-names>
            </name>
            <name>
              <surname>Heron</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Whitaker</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>McGraw</surname>
              <given-names>P.V.</given-names>
            </name>
          </person-group>
          <article-title>Asynchrony adaptation reveals neural population code for audiovisual timing</article-title>
          <source>Proceedings of the Royal Society B: Biological Sciences</source>
          <volume>278</volume>
          <issue>1710</issue>
          <year>2011</year>
          <fpage>1314</fpage>
          <lpage>1322</lpage>
          <pub-id pub-id-type="pmid">20961905</pub-id>
        </element-citation>
      </ref>
      <ref id="bib41">
        <element-citation publication-type="book" id="sref41">
          <person-group person-group-type="author">
            <name>
              <surname>Robertson</surname>
              <given-names>I.H.</given-names>
            </name>
          </person-group>
          <chapter-title>The Test of Everyday Attention</chapter-title>
          <year>2006</year>
          <publisher-name>Harcourt Assessment</publisher-name>
          <publisher-loc>London</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib42">
        <element-citation publication-type="journal" id="sref43a">
          <person-group person-group-type="author">
            <name>
              <surname>Scharnowski</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Rees</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Walsh</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Time and the brain: Neurorelativity</article-title>
          <source>Trends in Cognitive Sciences</source>
          <volume>17</volume>
          <issue>2</issue>
          <year>2013</year>
          <fpage>51</fpage>
          <lpage>52</lpage>
          <pub-id pub-id-type="pmid">23318094</pub-id>
        </element-citation>
      </ref>
      <ref id="bib43">
        <element-citation publication-type="journal" id="sref43">
          <person-group person-group-type="author">
            <name>
              <surname>Schneider</surname>
              <given-names>K.A.</given-names>
            </name>
            <name>
              <surname>Bavelier</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Components of visual prior entry</article-title>
          <source>Cognitive Psychology</source>
          <volume>47</volume>
          <issue>4</issue>
          <year>2003</year>
          <fpage>333</fpage>
          <lpage>366</lpage>
          <pub-id pub-id-type="pmid">14642288</pub-id>
        </element-citation>
      </ref>
      <ref id="bib44">
        <element-citation publication-type="journal" id="sref44">
          <person-group person-group-type="author">
            <name>
              <surname>Sekuler</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Sekuler</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Lau</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Sound alters visual motion perception</article-title>
          <source>Nature</source>
          <volume>385</volume>
          <issue>23rd January</issue>
          <year>1997</year>
          <fpage>308</fpage>
          <pub-id pub-id-type="pmid">9002513</pub-id>
        </element-citation>
      </ref>
      <ref id="bib45">
        <element-citation publication-type="journal" id="sref45">
          <person-group person-group-type="author">
            <name>
              <surname>Sherwin</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Efron</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Temporal ordering deficits following anterior temporal lobectomy</article-title>
          <source>Brain and Language</source>
          <volume>11</volume>
          <issue>1</issue>
          <year>1980</year>
          <fpage>195</fpage>
          <lpage>203</lpage>
          <pub-id pub-id-type="pmid">7427719</pub-id>
        </element-citation>
      </ref>
      <ref id="bib46">
        <element-citation publication-type="journal" id="sref46">
          <person-group person-group-type="author">
            <name>
              <surname>Soto-Faraco</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Alsius</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Conscious access to the unisensory components of a cross-modal illusion</article-title>
          <source>NeuroReport</source>
          <volume>18</volume>
          <issue>4</issue>
          <year>2007</year>
          <fpage>347</fpage>
          <lpage>350</lpage>
          <pub-id pub-id-type="pmid">17435600</pub-id>
        </element-citation>
      </ref>
      <ref id="bib47">
        <element-citation publication-type="journal" id="sref47">
          <person-group person-group-type="author">
            <name>
              <surname>Soto-Faraco</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Alsius</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Deconstructing the McGurk&#x2013;MacDonald illusion</article-title>
          <source>Journal of Experimental Psychology: Human Perception and Performance</source>
          <volume>35</volume>
          <issue>2</issue>
          <year>2009</year>
          <fpage>580</fpage>
          <lpage>587</lpage>
          <pub-id pub-id-type="pmid">19331510</pub-id>
        </element-citation>
      </ref>
      <ref id="bib48">
        <element-citation publication-type="book" id="sref48">
          <person-group person-group-type="author">
            <name>
              <surname>Spence</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Ngo</surname>
              <given-names>M.K.</given-names>
            </name>
          </person-group>
          <chapter-title>Does attention or multisensory integration explain the crossmodal facilitation of masked visual target identification?</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Stein</surname>
              <given-names>B.E.</given-names>
            </name>
          </person-group>
          <source>The New Handbook of Multisensory Processing</source>
          <year>2012</year>
          <publisher-name>MIT Press</publisher-name>
          <publisher-loc>Cambridge, Mass.</publisher-loc>
          <fpage>345</fpage>
          <lpage>358</lpage>
        </element-citation>
      </ref>
      <ref id="bib49">
        <element-citation publication-type="journal" id="sref49">
          <person-group person-group-type="author">
            <name>
              <surname>Spence</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Parise</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Prior-entry: A review</article-title>
          <source>Consciousness and Cognition</source>
          <volume>19</volume>
          <issue>1</issue>
          <year>2010</year>
          <fpage>364</fpage>
          <lpage>379</lpage>
          <pub-id pub-id-type="pmid">20056554</pub-id>
        </element-citation>
      </ref>
      <ref id="bib50">
        <element-citation publication-type="journal" id="sref50">
          <person-group person-group-type="author">
            <name>
              <surname>Spence</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Shore</surname>
              <given-names>D.I.</given-names>
            </name>
            <name>
              <surname>Klein</surname>
              <given-names>R.M.</given-names>
            </name>
          </person-group>
          <article-title>Multisensory prior entry</article-title>
          <source>Journal of Experimental Psychology: General</source>
          <volume>130</volume>
          <issue>4</issue>
          <year>2001</year>
          <fpage>799</fpage>
          <lpage>832</lpage>
          <pub-id pub-id-type="pmid">11757881</pub-id>
        </element-citation>
      </ref>
      <ref id="bib51">
        <element-citation publication-type="journal" id="sref51">
          <person-group person-group-type="author">
            <name>
              <surname>Spence</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Squire</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Multisensory integration: Maintaining the perception of synchrony</article-title>
          <source>Current Biology</source>
          <volume>13</volume>
          <issue>13</issue>
          <year>2003</year>
          <fpage>R519</fpage>
          <lpage>R521</lpage>
          <pub-id pub-id-type="pmid">12842029</pub-id>
        </element-citation>
      </ref>
      <ref id="bib52">
        <element-citation publication-type="book" id="sref52">
          <person-group person-group-type="author">
            <name>
              <surname>Spreen</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Benton</surname>
              <given-names>A.L.</given-names>
            </name>
          </person-group>
          <chapter-title>Neurosensory Centre Comprehensive Examination for Aphasia</chapter-title>
          <year>1969</year>
          <publisher-name>Neuropsychology Laboratory, University of Victoria</publisher-name>
          <publisher-loc>Victoria, British Columbia</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib53">
        <element-citation publication-type="book" id="sref53">
          <person-group person-group-type="author">
            <name>
              <surname>Sternberg</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Knoll</surname>
              <given-names>R.L.</given-names>
            </name>
          </person-group>
          <chapter-title>The perception of temporal order: Fundamental issues and a general model</chapter-title>
          <person-group person-group-type="editor">
            <name>
              <surname>Kornblum</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <source>Attention and Performance IV</source>
          <year>1973</year>
          <fpage>629</fpage>
          <lpage>685</lpage>
        </element-citation>
      </ref>
      <ref id="bib54">
        <element-citation publication-type="journal" id="sref54">
          <person-group person-group-type="author">
            <name>
              <surname>Stevenson</surname>
              <given-names>R.A.</given-names>
            </name>
            <name>
              <surname>Altieri</surname>
              <given-names>N.A.</given-names>
            </name>
            <name>
              <surname>Kim</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Pisoni</surname>
              <given-names>D.B.</given-names>
            </name>
            <name>
              <surname>James</surname>
              <given-names>T.W.</given-names>
            </name>
          </person-group>
          <article-title>Neural processing of asynchronous audiovisual speech perception</article-title>
          <source>NeuroImage</source>
          <volume>49</volume>
          <issue>4</issue>
          <year>2010</year>
          <fpage>3308</fpage>
          <lpage>3318</lpage>
          <pub-id pub-id-type="pmid">20004723</pub-id>
        </element-citation>
      </ref>
      <ref id="bib55">
        <element-citation publication-type="journal" id="sref55">
          <person-group person-group-type="author">
            <name>
              <surname>Stone</surname>
              <given-names>J.V.</given-names>
            </name>
            <name>
              <surname>Hunkin</surname>
              <given-names>N.M.</given-names>
            </name>
            <name>
              <surname>Porrill</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Wood</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Keeler</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Beanland</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>When is now? Perception of simultaneity</article-title>
          <source>Proceedings of the Royal Society B: Biological Sciences</source>
          <volume>268</volume>
          <issue>1462</issue>
          <year>2001</year>
          <fpage>31</fpage>
          <lpage>38</lpage>
          <pub-id pub-id-type="pmid">12123295</pub-id>
        </element-citation>
      </ref>
      <ref id="bib56">
        <element-citation publication-type="journal" id="sref56">
          <person-group person-group-type="author">
            <name>
              <surname>Sugita</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Suzuki</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Implicit estimation of sound-arrival time</article-title>
          <source>Nature</source>
          <volume>421</volume>
          <issue>6926</issue>
          <year>2003</year>
          <fpage>911</fpage>
          <pub-id pub-id-type="pmid">12606990</pub-id>
        </element-citation>
      </ref>
      <ref id="bib57">
        <element-citation publication-type="journal" id="sref57">
          <person-group person-group-type="author">
            <name>
              <surname>Sumby</surname>
              <given-names>W.H.</given-names>
            </name>
            <name>
              <surname>Pollack</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Visual contribution to speech intelligibility in noise</article-title>
          <source>Journal of the Acoustical Society of America</source>
          <volume>26</volume>
          <issue>2</issue>
          <year>1954</year>
          <fpage>212</fpage>
          <lpage>215</lpage>
        </element-citation>
      </ref>
      <ref id="bib58">
        <element-citation publication-type="journal" id="sref58">
          <person-group person-group-type="author">
            <name>
              <surname>Teki</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Grube</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Griffiths</surname>
              <given-names>T.D.</given-names>
            </name>
          </person-group>
          <article-title>A unified model of time perception accounts for duration-based and beat-based timing mechanisms</article-title>
          <source>Frontiers in Integrative Neuroscience</source>
          <volume>5</volume>
          <issue>January</issue>
          <year>2011</year>
          <fpage>90</fpage>
          <pub-id pub-id-type="pmid">22319477</pub-id>
        </element-citation>
      </ref>
      <ref id="bib59">
        <element-citation publication-type="book" id="sref59">
          <person-group person-group-type="author">
            <collab>The Psychological Corporation</collab>
          </person-group>
          <chapter-title>Wechsler Abbreviated Scale of Intelligence</chapter-title>
          <year>1999</year>
          <publisher-name>Harcourt Brace &amp; Co.</publisher-name>
          <publisher-loc>San Antonio</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib60">
        <element-citation publication-type="journal" id="sref60">
          <person-group person-group-type="author">
            <name>
              <surname>Treisman</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Temporal discrimination and the indifference interval. Implications for a model of the &#x201C;internal clock&#x201D;</article-title>
          <source>Psychological Monographs</source>
          <volume>77</volume>
          <issue>13</issue>
          <year>1963</year>
          <fpage>1</fpage>
          <lpage>31</lpage>
          <pub-id pub-id-type="pmid">5877542</pub-id>
        </element-citation>
      </ref>
      <ref id="bib61">
        <element-citation publication-type="journal" id="sref61">
          <person-group person-group-type="author">
            <name>
              <surname>van Eijk</surname>
              <given-names>R.L.J.</given-names>
            </name>
            <name>
              <surname>Kohlrausch</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Juola</surname>
              <given-names>J.F.</given-names>
            </name>
            <name>
              <surname>van De Par</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Audiovisual synchrony and temporal order judgments: Effects of experimental method and stimulus type</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>70</volume>
          <issue>6</issue>
          <year>2008</year>
          <fpage>955</fpage>
          <lpage>968</lpage>
          <pub-id pub-id-type="pmid">18717383</pub-id>
        </element-citation>
      </ref>
      <ref id="bib62">
        <element-citation publication-type="journal" id="sref62">
          <person-group person-group-type="author">
            <name>
              <surname>van Wassenhove</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Grant</surname>
              <given-names>K.W.</given-names>
            </name>
            <name>
              <surname>Poeppel</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Temporal window of integration in auditory&#x2013;visual speech perception</article-title>
          <source>Neuropsychologia</source>
          <volume>45</volume>
          <issue>3</issue>
          <year>2007</year>
          <fpage>598</fpage>
          <lpage>607</lpage>
          <pub-id pub-id-type="pmid">16530232</pub-id>
        </element-citation>
      </ref>
      <ref id="bib63">
        <element-citation publication-type="journal" id="sref63">
          <person-group person-group-type="author">
            <name>
              <surname>Vatakis</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Ghazanfar</surname>
              <given-names>A.A.</given-names>
            </name>
            <name>
              <surname>Spence</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Facilitation of multisensory integration by the &#x201C;unity effect&#x201D; reveals that speech is special</article-title>
          <source>Journal of Vision</source>
          <volume>8</volume>
          <issue>9</issue>
          <year>2008</year>
          <fpage>1</fpage>
          <lpage>11</lpage>
          <pub-id pub-id-type="pmid">18831650</pub-id>
        </element-citation>
      </ref>
      <ref id="bib64">
        <element-citation publication-type="journal" id="sref64">
          <person-group person-group-type="author">
            <name>
              <surname>Vatakis</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Spence</surname>
              <given-names>C.</given-names>
            </name>
          </person-group>
          <article-title>Crossmodal binding: Evaluating the &#x201C;unity assumption&#x201D; using audiovisual speech stimuli</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>69</volume>
          <issue>5</issue>
          <year>2007</year>
          <fpage>744</fpage>
          <lpage>756</lpage>
          <pub-id pub-id-type="pmid">17929697</pub-id>
        </element-citation>
      </ref>
      <ref id="bib65">
        <element-citation publication-type="journal" id="sref65">
          <person-group person-group-type="author">
            <name>
              <surname>Vroomen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>De Gelder</surname>
              <given-names>B.</given-names>
            </name>
          </person-group>
          <article-title>Temporal ventriloquism: Sound modulates the flash-lag effect</article-title>
          <source>Journal of Experimental Psychology: Human Perception and Performance</source>
          <volume>30</volume>
          <issue>3</issue>
          <year>2004</year>
          <fpage>513</fpage>
          <lpage>518</lpage>
          <pub-id pub-id-type="pmid">15161383</pub-id>
        </element-citation>
      </ref>
      <ref id="bib66">
        <element-citation publication-type="journal" id="sref66">
          <person-group person-group-type="author">
            <name>
              <surname>Vroomen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Keetels</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Perception of intersensory synchrony: A tutorial review</article-title>
          <source>Attention, Perception, &amp; Psychophysics</source>
          <volume>72</volume>
          <issue>4</issue>
          <year>2010</year>
          <fpage>871</fpage>
        </element-citation>
      </ref>
      <ref id="bib67">
        <element-citation publication-type="journal" id="sref67">
          <person-group person-group-type="author">
            <name>
              <surname>Vroomen</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Stekelenburg</surname>
              <given-names>J.J.</given-names>
            </name>
          </person-group>
          <article-title>Perception of intersensory synchrony in audiovisual speech: Not that special</article-title>
          <source>Cognition</source>
          <volume>118</volume>
          <issue>1</issue>
          <year>2011</year>
          <fpage>75</fpage>
          <lpage>83</lpage>
          <pub-id pub-id-type="pmid">21035795</pub-id>
        </element-citation>
      </ref>
      <ref id="bib68">
        <element-citation publication-type="book" id="sref68">
          <person-group person-group-type="author">
            <name>
              <surname>Warrington</surname>
              <given-names>E.K.</given-names>
            </name>
            <name>
              <surname>James</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <chapter-title>The Visual Object and Space Perception Battery</chapter-title>
          <year>1991</year>
          <publisher-name>Thames Valley Test Company</publisher-name>
          <publisher-loc>Bury St Edmunds</publisher-loc>
        </element-citation>
      </ref>
      <ref id="bib69">
        <element-citation publication-type="journal" id="sref69">
          <person-group person-group-type="author">
            <name>
              <surname>Welch</surname>
              <given-names>R.B.</given-names>
            </name>
            <name>
              <surname>Warren</surname>
              <given-names>D.H.</given-names>
            </name>
          </person-group>
          <article-title>Immediate perceptual response to intersensory discrepancy</article-title>
          <source>Psychological Bulletin</source>
          <volume>88</volume>
          <issue>3</issue>
          <year>1980</year>
          <fpage>638</fpage>
          <lpage>667</lpage>
          <pub-id pub-id-type="pmid">7003641</pub-id>
        </element-citation>
      </ref>
      <ref id="bib70">
        <element-citation publication-type="journal" id="sref70">
          <person-group person-group-type="author">
            <name>
              <surname>Wichmann</surname>
              <given-names>F.A.</given-names>
            </name>
            <name>
              <surname>Hill</surname>
              <given-names>N.J.</given-names>
            </name>
          </person-group>
          <article-title>The psychometric function: I. Fitting, sampling, and goodness of fit</article-title>
          <source>Perception &amp; Psychophysics</source>
          <volume>63</volume>
          <issue>8</issue>
          <year>2001</year>
          <fpage>1293</fpage>
          <lpage>1313</lpage>
          <pub-id pub-id-type="pmid">11800458</pub-id>
        </element-citation>
      </ref>
      <ref id="bib71">
        <element-citation publication-type="journal" id="sref71">
          <person-group person-group-type="author">
            <name>
              <surname>Wiener</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Matell</surname>
              <given-names>M.S.</given-names>
            </name>
            <name>
              <surname>Coslett</surname>
              <given-names>H.B.</given-names>
            </name>
          </person-group>
          <article-title>Multiple mechanisms for temporal processing</article-title>
          <source>Frontiers in Integrative Neuroscience</source>
          <volume>5</volume>
          <issue>July</issue>
          <year>2011</year>
          <fpage>1</fpage>
          <lpage>3</lpage>
          <pub-id pub-id-type="pmid">21369403</pub-id>
        </element-citation>
      </ref>
      <ref id="bib72">
        <element-citation publication-type="journal" id="sref72">
          <person-group person-group-type="author">
            <name>
              <surname>Witkin</surname>
              <given-names>H.A.</given-names>
            </name>
            <name>
              <surname>Wapner</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Leventhal</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Sound localization with conflicting visual and auditory cues</article-title>
          <source>Journal of Experimental Psychology</source>
          <volume>43</volume>
          <issue>1</issue>
          <year>1952</year>
          <fpage>58</fpage>
          <lpage>67</lpage>
          <pub-id pub-id-type="pmid">14907992</pub-id>
        </element-citation>
      </ref>
      <ref id="bib73">
        <element-citation publication-type="journal" id="sref73">
          <person-group person-group-type="author">
            <name>
              <surname>Yamamoto</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Miyazaki</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Iwano</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Kitazawa</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Bayesian calibration of simultaneity in audiovisual temporal order judgments</article-title>
          <source>PloS ONE</source>
          <volume>7</volume>
          <issue>7</issue>
          <year>2012</year>
          <fpage>e40379</fpage>
          <pub-id pub-id-type="pmid">22792297</pub-id>
        </element-citation>
      </ref>
      <ref id="bib74">
        <element-citation publication-type="journal" id="sref74">
          <person-group person-group-type="author">
            <name>
              <surname>Zeki</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Bartels</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>The asynchrony of consciousness</article-title>
          <source>Proceedings of the Royal Society B: Biological Sciences</source>
          <volume>265</volume>
          <issue>1405</issue>
          <year>1998</year>
          <fpage>1583</fpage>
          <lpage>1585</lpage>
          <pub-id pub-id-type="pmid">9744110</pub-id>
        </element-citation>
      </ref>
    </ref-list>
    <sec id="appsec1" sec-type="supplementary-material">
      <label>Appendix</label>
      <title>Supplementary data</title>
      <p>The following is the supplementary data related to this article:<supplementary-material content-type="local-data" id="ec1"><media xlink:href="mmc1.docx"/></supplementary-material></p>
    </sec>
    <ack id="ack0010">
      <title>Acknowledgements</title>
      <p>We thank P.H. for participating, and S. Khan, A. Alsius, R.&#xA0;Kanai and T. Schofield for technical assistance; and M.&#xA0;Cappelletti, D. Bueti, S. Gaigg, C. Haenschel, G. Rees, and C.&#xA0;Price, for critical discussions. J.D. was funded by a <funding-source id="gs1">Royal Society Leverhulme Trust Senior Research Fellowship</funding-source>. Imaging at the Wellcome Trust Centre for Neuroimaging, UCL, and open access publication, were supported by <funding-source id="gs2">Wellcome Centre grant</funding-source> 091593/Z/10/Z.</p>
    </ack>
    <fn-group>
      <fn id="appsec2" fn-type="supplementary-material">
        <label>Appendix</label>
        <p>Supplementary data related to this article can be found online at <ext-link ext-link-type="doi" xlink:href="10.1016/j.cortex.2013.03.006" id="intref0020">http://dx.doi.org/10.1016/j.cortex.2013.03.006</ext-link>.</p>
      </fn>
    </fn-group>
  </back>
  <floats-group>
    <fig id="fig1">
      <label>Fig.&#xA0;1</label>
      <caption>
        <p>T2 weighted images of both lesion sites, outlined in red.</p>
      </caption>
      <graphic xlink:href="gr1"/>
    </fig>
    <fig id="fig2">
      <label>Fig.&#xA0;2</label>
      <caption>
        <p>Trial sequence and stimuli for McGurk (top row) and Stream&#x2013;Bounce illusions (bottom).</p>
      </caption>
      <graphic xlink:href="gr2"/>
    </fig>
    <fig id="fig3">
      <label>Fig.&#xA0;3</label>
      <caption>
        <p>Psychometric data for PH (with black data points and interpolation using a broken line), and for healthy young (black continuous function) and older (grey) groups. a) TOJ: proportion of &#x2018;voice second&#x2019; reports (<italic>y</italic>-axis) for different auditory lags (negative <italic>x</italic>-values for auditory lead), interpolated with a logistic function. Horizontals indicate the PSS&#xA0;with 95% confidence intervals based on bootstrapped estimates for PH and on SEMean for controls. b) Phoneme discrimination task: proportion of responses following lip-movement, averaged across incongruous conditions only, interpolated using ADS functions. Auditory lag for tMcG&#xA0;was read off at the maximum.</p>
      </caption>
      <graphic xlink:href="gr3"/>
    </fig>
    <fig id="fig4">
      <label>Fig.&#xA0;4</label>
      <caption>
        <p>PSS (<italic>x</italic>-axis) plotted against asynchrony for maximum a) McGurk, i.e., tMcG (open circle: PH; grey: older; black: young) and b) bounce illusions (tBounce) with line of best fit, and marginal histograms.</p>
      </caption>
      <graphic xlink:href="gr4"/>
    </fig>
    <fig id="fig5">
      <label>Fig.&#xA0;5</label>
      <caption>
        <p>Temporal renormalisation theory: hypothetical relationship between neural and subjective audiovisual asynchrony. Top left: signals from synchronous auditory and visual stimuli (represented by blue and red disks) converge on different audiovisual mechanisms in the brain via different routes (grey disks). For individual mechanisms the actual stimulus timing cannot be dissociated from the propagation latency. Top right: schematic of the evoked distribution of neural asynchronies, across mechanisms, plotting probability of different asynchronies, as a function of neural asynchrony, with increasing delays of auditory signals relative to visual towards the right. The <italic>x</italic>-axis text refers to the <italic>subjective</italic> experience of auditory lead, simultaneity, or auditory lag, given these different neural asynchronies. The neural asynchrony at the central tendency of the distribution is the one which relates most reliably to the objective timing of the auditory and visual stimuli, after delays within individual mechanisms have been averaged out. Following experience with this distribution in natural contexts where objective synchrony is likely, tasks probing mechanisms registering asynchronies near this average may evoke perception of synchrony (marked with a dotted line and &#x2018;Simult&#x2019;); asynchronies registered within other mechanisms are perceived in proportion to their distance from the average. Lower left: an example where auditory inputs to a subset of mechanisms (towards the right) are particularly delayed. For patient PH it is assumed that these mechanisms contribute to the temporal tuning of the McGurk illusion (labelled McG; see main text), while mechanisms involved in TOJ are preserved. Lower right: the bimodal distribution resulting from delayed auditory input for the McGurk task. The mean of the distribution has shifted towards the auditory-lagged mechanisms serving the McGurk task (labelled McG). The perceived asynchrony within each mechanism is renormalised to this new distribution mean. The result is that neural asynchronies for unaffected mechanisms (here labelled TOJ) originally perceived as synchronous (as in the top example) are now perceived as auditory leading.</p>
      </caption>
      <graphic xlink:href="gr5"/>
    </fig>
    <table-wrap id="tbl1" position="float">
      <label>Table 1</label>
      <caption>
        <p>Neuropsychological test results for PH.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th>Test</th>
            <th>PH</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Wechsler abbreviated scale of intelligence (<xref rid="bib59" ref-type="bibr">The Psychological Corporation, 1999</xref>)</td>
            <td/>
          </tr>
          <tr>
            <td>&#xA0;Full scale IQ</td>
            <td>136</td>
          </tr>
          <tr>
            <td>&#xA0;Verbal IQ</td>
            <td>133</td>
          </tr>
          <tr>
            <td>&#xA0;Performance IQ</td>
            <td>129</td>
          </tr>
          <tr>
            <td colspan="2">&#x2028;&#x2028;</td>
          </tr>
          <tr>
            <td>Test of everyday attention</td>
            <td/>
          </tr>
          <tr>
            <td>&#xA0;Elevator counting</td>
            <td>6/7</td>
          </tr>
          <tr>
            <td>&#xA0;Elevator counting with distraction</td>
            <td>10/10</td>
          </tr>
          <tr>
            <td colspan="2">&#x2028;&#x2028;</td>
          </tr>
          <tr>
            <td>Visual Object and Space Perception Battery (<xref rid="bib68" ref-type="bibr">Warrington and James, 1991</xref>)</td>
            <td/>
          </tr>
          <tr>
            <td>&#xA0;Shape detection</td>
            <td>20/20</td>
          </tr>
          <tr>
            <td>&#xA0;Incomplete Letters</td>
            <td>20/20</td>
          </tr>
          <tr>
            <td>&#xA0;Silhouettes</td>
            <td>19/30</td>
          </tr>
          <tr>
            <td>&#xA0;Object decision</td>
            <td>19/20</td>
          </tr>
          <tr>
            <td>&#xA0;Dot counting</td>
            <td>10/10</td>
          </tr>
          <tr>
            <td>&#xA0;Position discrimination</td>
            <td>20/20</td>
          </tr>
          <tr>
            <td>&#xA0;Number location</td>
            <td>9/10</td>
          </tr>
          <tr>
            <td>&#xA0;Cube analysis</td>
            <td>10/10</td>
          </tr>
          <tr>
            <td colspan="2">&#x2028;&#x2028;</td>
          </tr>
          <tr>
            <td>Sentence repetition (auditory only)</td>
            <td>22/22</td>
          </tr>
          <tr>
            <td>Low&#xA0;+&#xA0;high frequency word repetition</td>
            <td>100%</td>
          </tr>
          <tr>
            <td colspan="2">&#x2028;&#x2028;</td>
          </tr>
          <tr>
            <td>Praxis</td>
            <td>Normal</td>
          </tr>
        </tbody>
      </table>
    </table-wrap>
    <table-wrap id="tbl2" position="float">
      <label>Table 2</label>
      <caption>
        <p>Mean results from McGurk experiment.</p>
      </caption>
      <table frame="hsides" rules="groups">
        <thead>
          <tr>
            <th/>
            <th>
              <italic>N</italic>
            </th>
            <th>PSS<xref rid="tbl2fna" ref-type="table-fn">a</xref></th>
            <th>CI<xref rid="tbl2fnb" ref-type="table-fn">b</xref></th>
            <th>JND<xref rid="tbl2fnc" ref-type="table-fn">c</xref></th>
            <th>CI</th>
            <th>tMcG<xref rid="tbl2fnd" ref-type="table-fn">d</xref></th>
            <th>CI</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>PH</td>
            <td align="char">1</td>
            <td align="char">210</td>
            <td align="char">&#xB1;40</td>
            <td align="char">93</td>
            <td align="char">&#xB1;35</td>
            <td align="char">&#x2212;240</td>
            <td align="char">&#xB1;56</td>
          </tr>
          <tr>
            <td>Older</td>
            <td align="char">10</td>
            <td align="char">19</td>
            <td align="char">&#xB1;94</td>
            <td align="char">176</td>
            <td align="char">&#xB1;64</td>
            <td align="char">21</td>
            <td align="char">&#xB1;78</td>
          </tr>
          <tr>
            <td>Younger</td>
            <td align="char">27</td>
            <td align="char">31</td>
            <td align="char">&#xB1;57</td>
            <td align="char">272</td>
            <td align="char">&#xB1;81</td>
            <td align="char">62</td>
            <td align="char">&#xB1;42</td>
          </tr>
        </tbody>
      </table>
      <table-wrap-foot>
        <fn id="tbl2fna">
          <label>a</label>
          <p>PSS, in milliseconds; positive values for auditory lag, negative for auditory lead.</p>
        </fn>
      </table-wrap-foot>
      <table-wrap-foot>
        <fn id="tbl2fnb">
          <label>b</label>
          <p>CI: 95% confidence interval (msec); estimated for PH by bootstrapping and for controls from SEMean.</p>
        </fn>
      </table-wrap-foot>
      <table-wrap-foot>
        <fn id="tbl2fnc">
          <label>c</label>
          <p>JND&#xA0;from subjective simultaneity (msec).</p>
        </fn>
      </table-wrap-foot>
      <table-wrap-foot>
        <fn id="tbl2fnd">
          <label>d</label>
          <p>tMcG: asynchrony for maximum McGurk effect (msec). Positive values for auditory lag.</p>
        </fn>
      </table-wrap-foot>
    </table-wrap>
  </floats-group>
</article>
</pmc-articleset>
